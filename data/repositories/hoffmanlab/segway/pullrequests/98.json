{"rendered": {"description": {"raw": "## Introduction\r\n\r\nThis pull request implements virtual evidence during training \\(disabled during identification\\). It is partly \\(namely the VE structure\\) based off of Max Libbrecht's measure-prop branch.  \r\nSpecifically, a binary virtual evidence node C has been added, which supplies the prior probability that the parent \\(segment label\\) A at a particular position is a particular label \\(ie P\\(C=1|A=a\\)\\).\r\n\r\nIn other words, the binary virtual child C exists only to constrain the parent \\(segment label\\) to be a particular value \\(supervised label\\) with the specified prior probability.\r\n\r\nI have also added a presence node such that positions with no prior specified by the user will have no virtual evidence.\r\n\r\nThe revised part of the graphical model is as below, where Qt is the segment label at position t, Ct is the virtual evidence child, and oCt indicates the presence of Ct. The black dotted line indicates a deterministic dependence where the parent of Ct switches based on the value of oCt; the red line indicates a stochastic conditional dependence \\(as there is a different Ct|Qt CPT at each t.\\) \r\n\r\n![](data/bitbucket.org/repo/a7MnLo/images/3913472725-graph_changes.png)\r\n## User changes\r\n\r\nThere are no changes to users without VE.\r\n\r\nIf a user wishes to use virtual evidence, they should supply a 'virtual evidence file' to Segway with the option `--virtual-evidence`. This virtual evidence file should be of BED3 format where the 4th column is a string containing the label:prior pairs the user wishes to specify, delimited by commas. For example,\r\n\r\n```\r\nchr1    0    1000    0:0.9,1:0.05\r\n```\r\n\r\nSpecifies a prior probability of 0.9 on label 0 and 0.05 on label 1 at chr1\\(0,1000\\).\r\n\r\nAt positions for which some labels are given a prior by the user but other labels not, the remaining probability is uniformly distributed amongst the leftover labels. For example, with 4 labels:\r\n\r\n```\r\nchr1    0    1000    0:0.4\r\n```\r\n\r\nall labels but label 0 would be given a prior probability of \\(1-0.4\\)/3=0.2.\r\n\r\nFor positions at which no prior is specified for all labels, a uniform probability is computed and distributed amongst the labels \\(though given 0 weight by Segway later due to the presence variable\\).\r\n\r\n## How it works\r\n\r\nVirtual evidence is similar to supervision in that values need to be supplied at each GMTK frame \\(with multiple frames per Segway window\\). However, the values supplied are CPTs, not observations, and so it does not work \\(as far as I know\\) to place them in the usual int/float observation files.\r\n\r\nTo this end, I used Segway's existing temporary observation files framework to create temporary CPTs \\(one large CPT per window, with one vector of priors for each GMTK frame in that window\\) and a list of these CPTs \\(`virtual_evidence_list_filename`\\).\r\n\r\nDuring training, the cpp directive `VIRTUAL_EVIDENCE_LIST_FILENAME` is given a value of `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` when creating the task to send to segway-task. `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` is then replaced within the cppCommand string with the temporarily created `virtual_evidence_list_filename` \\(with its list of CPTs per window\\).\r\n\r\nThe presence for virtual evidence is supplied identically as for data and supervision labels--appended to the int block and subsequently passed forwards to GMTK for use.\r\n\r\n## Resolution and downsampling\r\n\r\nIn order to downsample virtual evidence \\(`get_downsampled_virtual_evidence_data_and_presence`\\), I decided to implement the following rule:\r\n\r\nLet resolution be greater than 1. For positions which have some priors specified but not all, compute uniform priors for the remaining labels and take the average prior probability \\(over the position axis\\) over these positions. The presence is then the number of positions that have any priors specified.\r\n\r\nFor example, with 3 total labels with resolution 10:\r\n\r\n```\r\nchr1    0   1    0:0.5,1:0.2\r\nchr1    1    2    1:0.4\r\n```\r\n\r\nthis expands \\(inferring uniform priors for remaining labels\\) into:\r\n\r\n```\r\nlabel           0   1   2\r\nchr1    0   1   0.5 0.2 0.3\r\nchr1    1   2   0.3 0.4 0.3\r\n```\r\n\r\nwe take the average over these positions to obtain:\r\n\r\n```\r\nchr1    0   10  0.4 0.3 0.4\r\n```\r\n\r\nwith presence 2.\r\n\r\nNow let resolution equal 1. Then the presence is simply 1 or 0; 1 for positions with priors specified, and 0 for positions without. For positions with priors specified, uniform priors are inferred for any remaining labels, and this becomes the prior vector for that position.\r\n\r\nIn both cases, positions with no priors specified are given 0 presence and uniform priors for all labels.\r\n\r\n## Test case\r\n\r\nFollowing discussion with Eric, I created the following virtual evidence bedfile and supplied it to simpleseg:\r\n\r\n```\r\nchr1    0   1000    0:0.9\r\nchr1    4000    5000    0:0.9\r\n```\r\n\r\nThis is able to separate the binary 0,0 and 0,1 regions in simpleseg, creating the following annotation:\r\n\r\n```\r\nchr1    0   1000    0   1000    .   0   1000    27,158,119\r\nchr1    1000    2000    1   1000    .   1000    2000    217,95,2\r\nchr1    2000    3000    2   1000    .   2000    3000    117,112,179\r\nchr1    3000    4000    3   1000    .   3000    4000    231,41,138\r\nchr1    4000    5000    0   1000    .   4000    5000    27,158,119\r\nchr1    5000    6000    1   1000    .   5000    6000    217,95,2\r\nchr1    6000    7000    2   1000    .   6000    7000    117,112,179\r\nchr1    7000    8000    3   1000    .   7000    8000    231,41,138\r\n```\r\n\r\nI have named this test case `simplevirtualevidence`.\r\n\r\n## Remaining work\r\n\r\nAs discussed with Max Libbrecht over email, it might be interesting to enable VE during identification \\(allowing priors to influence Viterbi\\) in a future PR.", "markup": "markdown", "html": "<h2 id=\"markdown-header-introduction\">Introduction</h2>\n<p>This pull request implements virtual evidence during training (disabled during identification). It is partly (namely the VE structure) based off of Max Libbrecht's measure-prop branch.<br />\nSpecifically, a binary virtual evidence node C has been added, which supplies the prior probability that the parent (segment label) A at a particular position is a particular label (ie P(C=1|A=a)).</p>\n<p>In other words, the binary virtual child C exists only to constrain the parent (segment label) to be a particular value (supervised label) with the specified prior probability.</p>\n<p>I have also added a presence node such that positions with no prior specified by the user will have no virtual evidence.</p>\n<p>The revised part of the graphical model is as below, where Qt is the segment label at position t, Ct is the virtual evidence child, and oCt indicates the presence of Ct. The black dotted line indicates a deterministic dependence where the parent of Ct switches based on the value of oCt; the red line indicates a stochastic conditional dependence (as there is a different Ct|Qt CPT at each t.) </p>\n<p><img alt=\"\" src=\"data/bitbucket.org/repo/a7MnLo/images/3913472725-graph_changes.png\" /></p>\n<h2 id=\"markdown-header-user-changes\">User changes</h2>\n<p>There are no changes to users without VE.</p>\n<p>If a user wishes to use virtual evidence, they should supply a 'virtual evidence file' to Segway with the option <code>--virtual-evidence</code>. This virtual evidence file should be of BED3 format where the 4th column is a string containing the label:prior pairs the user wishes to specify, delimited by commas. For example,</p>\n<div class=\"codehilite\"><pre><span></span>chr1    0    1000    0:0.9,1:0.05\n</pre></div>\n\n\n<p>Specifies a prior probability of 0.9 on label 0 and 0.05 on label 1 at chr1(0,1000).</p>\n<p>At positions for which some labels are given a prior by the user but other labels not, the remaining probability is uniformly distributed amongst the leftover labels. For example, with 4 labels:</p>\n<div class=\"codehilite\"><pre><span></span>chr1    0    1000    0:0.4\n</pre></div>\n\n\n<p>all labels but label 0 would be given a prior probability of (1-0.4)/3=0.2.</p>\n<p>For positions at which no prior is specified for all labels, a uniform probability is computed and distributed amongst the labels (though given 0 weight by Segway later due to the presence variable).</p>\n<h2 id=\"markdown-header-how-it-works\">How it works</h2>\n<p>Virtual evidence is similar to supervision in that values need to be supplied at each GMTK frame (with multiple frames per Segway window). However, the values supplied are CPTs, not observations, and so it does not work (as far as I know) to place them in the usual int/float observation files.</p>\n<p>To this end, I used Segway's existing temporary observation files framework to create temporary CPTs (one large CPT per window, with one vector of priors for each GMTK frame in that window) and a list of these CPTs (<code>virtual_evidence_list_filename</code>).</p>\n<p>During training, the cpp directive <code>VIRTUAL_EVIDENCE_LIST_FILENAME</code> is given a value of <code>VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER</code> when creating the task to send to segway-task. <code>VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER</code> is then replaced within the cppCommand string with the temporarily created <code>virtual_evidence_list_filename</code> (with its list of CPTs per window).</p>\n<p>The presence for virtual evidence is supplied identically as for data and supervision labels--appended to the int block and subsequently passed forwards to GMTK for use.</p>\n<h2 id=\"markdown-header-resolution-and-downsampling\">Resolution and downsampling</h2>\n<p>In order to downsample virtual evidence (<code>get_downsampled_virtual_evidence_data_and_presence</code>), I decided to implement the following rule:</p>\n<p>Let resolution be greater than 1. For positions which have some priors specified but not all, compute uniform priors for the remaining labels and take the average prior probability (over the position axis) over these positions. The presence is then the number of positions that have any priors specified.</p>\n<p>For example, with 3 total labels with resolution 10:</p>\n<div class=\"codehilite\"><pre><span></span>chr1    0   1    0:0.5,1:0.2\nchr1    1    2    1:0.4\n</pre></div>\n\n\n<p>this expands (inferring uniform priors for remaining labels) into:</p>\n<div class=\"codehilite\"><pre><span></span>label           0   1   2\nchr1    0   1   0.5 0.2 0.3\nchr1    1   2   0.3 0.4 0.3\n</pre></div>\n\n\n<p>we take the average over these positions to obtain:</p>\n<div class=\"codehilite\"><pre><span></span>chr1    0   10  0.4 0.3 0.4\n</pre></div>\n\n\n<p>with presence 2.</p>\n<p>Now let resolution equal 1. Then the presence is simply 1 or 0; 1 for positions with priors specified, and 0 for positions without. For positions with priors specified, uniform priors are inferred for any remaining labels, and this becomes the prior vector for that position.</p>\n<p>In both cases, positions with no priors specified are given 0 presence and uniform priors for all labels.</p>\n<h2 id=\"markdown-header-test-case\">Test case</h2>\n<p>Following discussion with Eric, I created the following virtual evidence bedfile and supplied it to simpleseg:</p>\n<div class=\"codehilite\"><pre><span></span>chr1    0   1000    0:0.9\nchr1    4000    5000    0:0.9\n</pre></div>\n\n\n<p>This is able to separate the binary 0,0 and 0,1 regions in simpleseg, creating the following annotation:</p>\n<div class=\"codehilite\"><pre><span></span>chr1    0   1000    0   1000    .   0   1000    27,158,119\nchr1    1000    2000    1   1000    .   1000    2000    217,95,2\nchr1    2000    3000    2   1000    .   2000    3000    117,112,179\nchr1    3000    4000    3   1000    .   3000    4000    231,41,138\nchr1    4000    5000    0   1000    .   4000    5000    27,158,119\nchr1    5000    6000    1   1000    .   5000    6000    217,95,2\nchr1    6000    7000    2   1000    .   6000    7000    117,112,179\nchr1    7000    8000    3   1000    .   7000    8000    231,41,138\n</pre></div>\n\n\n<p>I have named this test case <code>simplevirtualevidence</code>.</p>\n<h2 id=\"markdown-header-remaining-work\">Remaining work</h2>\n<p>As discussed with Max Libbrecht over email, it might be interesting to enable VE during identification (allowing priors to influence Viterbi) in a future PR.</p>", "type": "rendered"}, "title": {"raw": "Implement virtual evidence during training", "markup": "markdown", "html": "<p>Implement virtual evidence during training</p>", "type": "rendered"}}, "type": "pullrequest", "description": "## Introduction\r\n\r\nThis pull request implements virtual evidence during training \\(disabled during identification\\). It is partly \\(namely the VE structure\\) based off of Max Libbrecht's measure-prop branch.  \r\nSpecifically, a binary virtual evidence node C has been added, which supplies the prior probability that the parent \\(segment label\\) A at a particular position is a particular label \\(ie P\\(C=1|A=a\\)\\).\r\n\r\nIn other words, the binary virtual child C exists only to constrain the parent \\(segment label\\) to be a particular value \\(supervised label\\) with the specified prior probability.\r\n\r\nI have also added a presence node such that positions with no prior specified by the user will have no virtual evidence.\r\n\r\nThe revised part of the graphical model is as below, where Qt is the segment label at position t, Ct is the virtual evidence child, and oCt indicates the presence of Ct. The black dotted line indicates a deterministic dependence where the parent of Ct switches based on the value of oCt; the red line indicates a stochastic conditional dependence \\(as there is a different Ct|Qt CPT at each t.\\) \r\n\r\n![](data/bitbucket.org/repo/a7MnLo/images/3913472725-graph_changes.png)\r\n## User changes\r\n\r\nThere are no changes to users without VE.\r\n\r\nIf a user wishes to use virtual evidence, they should supply a 'virtual evidence file' to Segway with the option `--virtual-evidence`. This virtual evidence file should be of BED3 format where the 4th column is a string containing the label:prior pairs the user wishes to specify, delimited by commas. For example,\r\n\r\n```\r\nchr1    0    1000    0:0.9,1:0.05\r\n```\r\n\r\nSpecifies a prior probability of 0.9 on label 0 and 0.05 on label 1 at chr1\\(0,1000\\).\r\n\r\nAt positions for which some labels are given a prior by the user but other labels not, the remaining probability is uniformly distributed amongst the leftover labels. For example, with 4 labels:\r\n\r\n```\r\nchr1    0    1000    0:0.4\r\n```\r\n\r\nall labels but label 0 would be given a prior probability of \\(1-0.4\\)/3=0.2.\r\n\r\nFor positions at which no prior is specified for all labels, a uniform probability is computed and distributed amongst the labels \\(though given 0 weight by Segway later due to the presence variable\\).\r\n\r\n## How it works\r\n\r\nVirtual evidence is similar to supervision in that values need to be supplied at each GMTK frame \\(with multiple frames per Segway window\\). However, the values supplied are CPTs, not observations, and so it does not work \\(as far as I know\\) to place them in the usual int/float observation files.\r\n\r\nTo this end, I used Segway's existing temporary observation files framework to create temporary CPTs \\(one large CPT per window, with one vector of priors for each GMTK frame in that window\\) and a list of these CPTs \\(`virtual_evidence_list_filename`\\).\r\n\r\nDuring training, the cpp directive `VIRTUAL_EVIDENCE_LIST_FILENAME` is given a value of `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` when creating the task to send to segway-task. `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` is then replaced within the cppCommand string with the temporarily created `virtual_evidence_list_filename` \\(with its list of CPTs per window\\).\r\n\r\nThe presence for virtual evidence is supplied identically as for data and supervision labels--appended to the int block and subsequently passed forwards to GMTK for use.\r\n\r\n## Resolution and downsampling\r\n\r\nIn order to downsample virtual evidence \\(`get_downsampled_virtual_evidence_data_and_presence`\\), I decided to implement the following rule:\r\n\r\nLet resolution be greater than 1. For positions which have some priors specified but not all, compute uniform priors for the remaining labels and take the average prior probability \\(over the position axis\\) over these positions. The presence is then the number of positions that have any priors specified.\r\n\r\nFor example, with 3 total labels with resolution 10:\r\n\r\n```\r\nchr1    0   1    0:0.5,1:0.2\r\nchr1    1    2    1:0.4\r\n```\r\n\r\nthis expands \\(inferring uniform priors for remaining labels\\) into:\r\n\r\n```\r\nlabel           0   1   2\r\nchr1    0   1   0.5 0.2 0.3\r\nchr1    1   2   0.3 0.4 0.3\r\n```\r\n\r\nwe take the average over these positions to obtain:\r\n\r\n```\r\nchr1    0   10  0.4 0.3 0.4\r\n```\r\n\r\nwith presence 2.\r\n\r\nNow let resolution equal 1. Then the presence is simply 1 or 0; 1 for positions with priors specified, and 0 for positions without. For positions with priors specified, uniform priors are inferred for any remaining labels, and this becomes the prior vector for that position.\r\n\r\nIn both cases, positions with no priors specified are given 0 presence and uniform priors for all labels.\r\n\r\n## Test case\r\n\r\nFollowing discussion with Eric, I created the following virtual evidence bedfile and supplied it to simpleseg:\r\n\r\n```\r\nchr1    0   1000    0:0.9\r\nchr1    4000    5000    0:0.9\r\n```\r\n\r\nThis is able to separate the binary 0,0 and 0,1 regions in simpleseg, creating the following annotation:\r\n\r\n```\r\nchr1    0   1000    0   1000    .   0   1000    27,158,119\r\nchr1    1000    2000    1   1000    .   1000    2000    217,95,2\r\nchr1    2000    3000    2   1000    .   2000    3000    117,112,179\r\nchr1    3000    4000    3   1000    .   3000    4000    231,41,138\r\nchr1    4000    5000    0   1000    .   4000    5000    27,158,119\r\nchr1    5000    6000    1   1000    .   5000    6000    217,95,2\r\nchr1    6000    7000    2   1000    .   6000    7000    117,112,179\r\nchr1    7000    8000    3   1000    .   7000    8000    231,41,138\r\n```\r\n\r\nI have named this test case `simplevirtualevidence`.\r\n\r\n## Remaining work\r\n\r\nAs discussed with Max Libbrecht over email, it might be interesting to enable VE during identification \\(allowing priors to influence Viterbi\\) in a future PR.", "links": {"decline": {"href": "https://api.bitbucket.org/2.0/repositories/hoffmanlab/segway/pullrequests/98/decline"}, "diffstat": {"href": "https://api.bitbucket.org/2.0/repositories/hoffmanlab/segway/diffstat/rcwchan/segway:1defedc4139a%0Df04cce0da8be?from_pullrequest_id=98"}, "commits": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/commits.json"}, "self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "comments": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments_page=1.json"}, "merge": {"href": "https://api.bitbucket.org/2.0/repositories/hoffmanlab/segway/pullrequests/98/merge"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}, "activity": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/activity.json"}, "diff": {"href": "https://api.bitbucket.org/2.0/repositories/hoffmanlab/segway/diff/rcwchan/segway:1defedc4139a%0Df04cce0da8be?from_pullrequest_id=98"}, "approve": {"href": "https://api.bitbucket.org/2.0/repositories/hoffmanlab/segway/pullrequests/98/approve"}, "statuses": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/statuses_page=1.json"}}, "title": "Implement virtual evidence during training", "close_source_branch": true, "reviewers": [{"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}], "id": 98, "destination": {"commit": {"hash": "f04cce0da8be", "type": "commit", "links": {"self": {"href": "data/repositories/hoffmanlab/segway/commit/f04cce0da8be.json"}, "html": {"href": "#!/hoffmanlab/segway/commits/f04cce0da8be"}}}, "repository": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway.json"}, "html": {"href": "#!/hoffmanlab/segway"}, "avatar": {"href": "data/bytebucket.org/ravatar/{68bf38bf-f0c1-4c9c-909e-0ee4b2c26257}ts=python"}}, "type": "repository", "name": "segway", "full_name": "hoffmanlab/segway", "uuid": "{68bf38bf-f0c1-4c9c-909e-0ee4b2c26257}"}, "branch": {"name": "default"}}, "created_on": "2019-04-04T15:48:33.028561+00:00", "summary": {"raw": "## Introduction\r\n\r\nThis pull request implements virtual evidence during training \\(disabled during identification\\). It is partly \\(namely the VE structure\\) based off of Max Libbrecht's measure-prop branch.  \r\nSpecifically, a binary virtual evidence node C has been added, which supplies the prior probability that the parent \\(segment label\\) A at a particular position is a particular label \\(ie P\\(C=1|A=a\\)\\).\r\n\r\nIn other words, the binary virtual child C exists only to constrain the parent \\(segment label\\) to be a particular value \\(supervised label\\) with the specified prior probability.\r\n\r\nI have also added a presence node such that positions with no prior specified by the user will have no virtual evidence.\r\n\r\nThe revised part of the graphical model is as below, where Qt is the segment label at position t, Ct is the virtual evidence child, and oCt indicates the presence of Ct. The black dotted line indicates a deterministic dependence where the parent of Ct switches based on the value of oCt; the red line indicates a stochastic conditional dependence \\(as there is a different Ct|Qt CPT at each t.\\) \r\n\r\n![](data/bitbucket.org/repo/a7MnLo/images/3913472725-graph_changes.png)\r\n## User changes\r\n\r\nThere are no changes to users without VE.\r\n\r\nIf a user wishes to use virtual evidence, they should supply a 'virtual evidence file' to Segway with the option `--virtual-evidence`. This virtual evidence file should be of BED3 format where the 4th column is a string containing the label:prior pairs the user wishes to specify, delimited by commas. For example,\r\n\r\n```\r\nchr1    0    1000    0:0.9,1:0.05\r\n```\r\n\r\nSpecifies a prior probability of 0.9 on label 0 and 0.05 on label 1 at chr1\\(0,1000\\).\r\n\r\nAt positions for which some labels are given a prior by the user but other labels not, the remaining probability is uniformly distributed amongst the leftover labels. For example, with 4 labels:\r\n\r\n```\r\nchr1    0    1000    0:0.4\r\n```\r\n\r\nall labels but label 0 would be given a prior probability of \\(1-0.4\\)/3=0.2.\r\n\r\nFor positions at which no prior is specified for all labels, a uniform probability is computed and distributed amongst the labels \\(though given 0 weight by Segway later due to the presence variable\\).\r\n\r\n## How it works\r\n\r\nVirtual evidence is similar to supervision in that values need to be supplied at each GMTK frame \\(with multiple frames per Segway window\\). However, the values supplied are CPTs, not observations, and so it does not work \\(as far as I know\\) to place them in the usual int/float observation files.\r\n\r\nTo this end, I used Segway's existing temporary observation files framework to create temporary CPTs \\(one large CPT per window, with one vector of priors for each GMTK frame in that window\\) and a list of these CPTs \\(`virtual_evidence_list_filename`\\).\r\n\r\nDuring training, the cpp directive `VIRTUAL_EVIDENCE_LIST_FILENAME` is given a value of `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` when creating the task to send to segway-task. `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` is then replaced within the cppCommand string with the temporarily created `virtual_evidence_list_filename` \\(with its list of CPTs per window\\).\r\n\r\nThe presence for virtual evidence is supplied identically as for data and supervision labels--appended to the int block and subsequently passed forwards to GMTK for use.\r\n\r\n## Resolution and downsampling\r\n\r\nIn order to downsample virtual evidence \\(`get_downsampled_virtual_evidence_data_and_presence`\\), I decided to implement the following rule:\r\n\r\nLet resolution be greater than 1. For positions which have some priors specified but not all, compute uniform priors for the remaining labels and take the average prior probability \\(over the position axis\\) over these positions. The presence is then the number of positions that have any priors specified.\r\n\r\nFor example, with 3 total labels with resolution 10:\r\n\r\n```\r\nchr1    0   1    0:0.5,1:0.2\r\nchr1    1    2    1:0.4\r\n```\r\n\r\nthis expands \\(inferring uniform priors for remaining labels\\) into:\r\n\r\n```\r\nlabel           0   1   2\r\nchr1    0   1   0.5 0.2 0.3\r\nchr1    1   2   0.3 0.4 0.3\r\n```\r\n\r\nwe take the average over these positions to obtain:\r\n\r\n```\r\nchr1    0   10  0.4 0.3 0.4\r\n```\r\n\r\nwith presence 2.\r\n\r\nNow let resolution equal 1. Then the presence is simply 1 or 0; 1 for positions with priors specified, and 0 for positions without. For positions with priors specified, uniform priors are inferred for any remaining labels, and this becomes the prior vector for that position.\r\n\r\nIn both cases, positions with no priors specified are given 0 presence and uniform priors for all labels.\r\n\r\n## Test case\r\n\r\nFollowing discussion with Eric, I created the following virtual evidence bedfile and supplied it to simpleseg:\r\n\r\n```\r\nchr1    0   1000    0:0.9\r\nchr1    4000    5000    0:0.9\r\n```\r\n\r\nThis is able to separate the binary 0,0 and 0,1 regions in simpleseg, creating the following annotation:\r\n\r\n```\r\nchr1    0   1000    0   1000    .   0   1000    27,158,119\r\nchr1    1000    2000    1   1000    .   1000    2000    217,95,2\r\nchr1    2000    3000    2   1000    .   2000    3000    117,112,179\r\nchr1    3000    4000    3   1000    .   3000    4000    231,41,138\r\nchr1    4000    5000    0   1000    .   4000    5000    27,158,119\r\nchr1    5000    6000    1   1000    .   5000    6000    217,95,2\r\nchr1    6000    7000    2   1000    .   6000    7000    117,112,179\r\nchr1    7000    8000    3   1000    .   7000    8000    231,41,138\r\n```\r\n\r\nI have named this test case `simplevirtualevidence`.\r\n\r\n## Remaining work\r\n\r\nAs discussed with Max Libbrecht over email, it might be interesting to enable VE during identification \\(allowing priors to influence Viterbi\\) in a future PR.", "markup": "markdown", "html": "<h2 id=\"markdown-header-introduction\">Introduction</h2>\n<p>This pull request implements virtual evidence during training (disabled during identification). It is partly (namely the VE structure) based off of Max Libbrecht's measure-prop branch.<br />\nSpecifically, a binary virtual evidence node C has been added, which supplies the prior probability that the parent (segment label) A at a particular position is a particular label (ie P(C=1|A=a)).</p>\n<p>In other words, the binary virtual child C exists only to constrain the parent (segment label) to be a particular value (supervised label) with the specified prior probability.</p>\n<p>I have also added a presence node such that positions with no prior specified by the user will have no virtual evidence.</p>\n<p>The revised part of the graphical model is as below, where Qt is the segment label at position t, Ct is the virtual evidence child, and oCt indicates the presence of Ct. The black dotted line indicates a deterministic dependence where the parent of Ct switches based on the value of oCt; the red line indicates a stochastic conditional dependence (as there is a different Ct|Qt CPT at each t.) </p>\n<p><img alt=\"\" src=\"data/bitbucket.org/repo/a7MnLo/images/3913472725-graph_changes.png\" /></p>\n<h2 id=\"markdown-header-user-changes\">User changes</h2>\n<p>There are no changes to users without VE.</p>\n<p>If a user wishes to use virtual evidence, they should supply a 'virtual evidence file' to Segway with the option <code>--virtual-evidence</code>. This virtual evidence file should be of BED3 format where the 4th column is a string containing the label:prior pairs the user wishes to specify, delimited by commas. For example,</p>\n<div class=\"codehilite\"><pre><span></span>chr1    0    1000    0:0.9,1:0.05\n</pre></div>\n\n\n<p>Specifies a prior probability of 0.9 on label 0 and 0.05 on label 1 at chr1(0,1000).</p>\n<p>At positions for which some labels are given a prior by the user but other labels not, the remaining probability is uniformly distributed amongst the leftover labels. For example, with 4 labels:</p>\n<div class=\"codehilite\"><pre><span></span>chr1    0    1000    0:0.4\n</pre></div>\n\n\n<p>all labels but label 0 would be given a prior probability of (1-0.4)/3=0.2.</p>\n<p>For positions at which no prior is specified for all labels, a uniform probability is computed and distributed amongst the labels (though given 0 weight by Segway later due to the presence variable).</p>\n<h2 id=\"markdown-header-how-it-works\">How it works</h2>\n<p>Virtual evidence is similar to supervision in that values need to be supplied at each GMTK frame (with multiple frames per Segway window). However, the values supplied are CPTs, not observations, and so it does not work (as far as I know) to place them in the usual int/float observation files.</p>\n<p>To this end, I used Segway's existing temporary observation files framework to create temporary CPTs (one large CPT per window, with one vector of priors for each GMTK frame in that window) and a list of these CPTs (<code>virtual_evidence_list_filename</code>).</p>\n<p>During training, the cpp directive <code>VIRTUAL_EVIDENCE_LIST_FILENAME</code> is given a value of <code>VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER</code> when creating the task to send to segway-task. <code>VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER</code> is then replaced within the cppCommand string with the temporarily created <code>virtual_evidence_list_filename</code> (with its list of CPTs per window).</p>\n<p>The presence for virtual evidence is supplied identically as for data and supervision labels--appended to the int block and subsequently passed forwards to GMTK for use.</p>\n<h2 id=\"markdown-header-resolution-and-downsampling\">Resolution and downsampling</h2>\n<p>In order to downsample virtual evidence (<code>get_downsampled_virtual_evidence_data_and_presence</code>), I decided to implement the following rule:</p>\n<p>Let resolution be greater than 1. For positions which have some priors specified but not all, compute uniform priors for the remaining labels and take the average prior probability (over the position axis) over these positions. The presence is then the number of positions that have any priors specified.</p>\n<p>For example, with 3 total labels with resolution 10:</p>\n<div class=\"codehilite\"><pre><span></span>chr1    0   1    0:0.5,1:0.2\nchr1    1    2    1:0.4\n</pre></div>\n\n\n<p>this expands (inferring uniform priors for remaining labels) into:</p>\n<div class=\"codehilite\"><pre><span></span>label           0   1   2\nchr1    0   1   0.5 0.2 0.3\nchr1    1   2   0.3 0.4 0.3\n</pre></div>\n\n\n<p>we take the average over these positions to obtain:</p>\n<div class=\"codehilite\"><pre><span></span>chr1    0   10  0.4 0.3 0.4\n</pre></div>\n\n\n<p>with presence 2.</p>\n<p>Now let resolution equal 1. Then the presence is simply 1 or 0; 1 for positions with priors specified, and 0 for positions without. For positions with priors specified, uniform priors are inferred for any remaining labels, and this becomes the prior vector for that position.</p>\n<p>In both cases, positions with no priors specified are given 0 presence and uniform priors for all labels.</p>\n<h2 id=\"markdown-header-test-case\">Test case</h2>\n<p>Following discussion with Eric, I created the following virtual evidence bedfile and supplied it to simpleseg:</p>\n<div class=\"codehilite\"><pre><span></span>chr1    0   1000    0:0.9\nchr1    4000    5000    0:0.9\n</pre></div>\n\n\n<p>This is able to separate the binary 0,0 and 0,1 regions in simpleseg, creating the following annotation:</p>\n<div class=\"codehilite\"><pre><span></span>chr1    0   1000    0   1000    .   0   1000    27,158,119\nchr1    1000    2000    1   1000    .   1000    2000    217,95,2\nchr1    2000    3000    2   1000    .   2000    3000    117,112,179\nchr1    3000    4000    3   1000    .   3000    4000    231,41,138\nchr1    4000    5000    0   1000    .   4000    5000    27,158,119\nchr1    5000    6000    1   1000    .   5000    6000    217,95,2\nchr1    6000    7000    2   1000    .   6000    7000    117,112,179\nchr1    7000    8000    3   1000    .   7000    8000    231,41,138\n</pre></div>\n\n\n<p>I have named this test case <code>simplevirtualevidence</code>.</p>\n<h2 id=\"markdown-header-remaining-work\">Remaining work</h2>\n<p>As discussed with Max Libbrecht over email, it might be interesting to enable VE during identification (allowing priors to influence Viterbi) in a future PR.</p>", "type": "rendered"}, "source": {"commit": {"hash": "1defedc4139a", "type": "commit", "links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/rcwchan/segway/commit/1defedc4139a"}, "html": {"href": "https://bitbucket.org/rcwchan/segway/commits/1defedc4139a"}}}, "repository": {"links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/rcwchan/segway"}, "html": {"href": "https://bitbucket.org/rcwchan/segway"}, "avatar": {"href": "data/bytebucket.org/ravatar/{285886c8-7a4a-4d80-8fe1-3d4b0d9146f6}ts=python"}}, "type": "repository", "name": "segway", "full_name": "rcwchan/segway", "uuid": "{285886c8-7a4a-4d80-8fe1-3d4b0d9146f6}"}, "branch": {"name": "virtualevidence"}}, "comment_count": 54, "state": "OPEN", "task_count": 0, "participants": [{"role": "REVIEWER", "participated_on": "2019-04-16T20:12:44.490195+00:00", "type": "participant", "approved": false, "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}}, {"role": "PARTICIPANT", "participated_on": "2019-04-16T15:48:39.483708+00:00", "type": "participant", "approved": false, "user": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}}], "reason": "", "updated_on": "2019-07-29T15:00:39.023794+00:00", "author": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "merge_commit": null, "closed_by": null}
{"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/100/comments/118706621.json"}, "code": {"href": "https://api.bitbucket.org/2.0/repositories/hoffmanlab/segway/diff/mjmm13/segway_python23:3ba168e8350b..8cbdd3f79d65?path=segway%2Fobservations.py"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/100/_/diff#comment-118706621"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 100, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/100.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/100"}}, "title": "Implement virtual evidence for all segway tasks"}, "content": {"raw": "I am concerned about this approach--I assume that either things will add up to `1.0` exactly or that comparing with a slop of machine epsilon will not be enough given the number of operations that could have gone into these numbers. We could take two approaches here:\n\n1. we could just trust that the input at this stage is correct and let GMTK deal with any deviations from adding up to 1.0. I assume that it already does this just fine. We should check user input closer to the user but not here. I think I would favor this, if that\u2019s the case; or\n2. we could rescale `mean_prior_vector`, multiplying each cell by the inverse of `sum(mean_prior_vector)`. That would ensure it adds up to `1.0` as best we can manage.\n\n\u200c", "markup": "markdown", "html": "<p>I am concerned about this approach--I assume that either things will add up to <code>1.0</code> exactly or that comparing with a slop of machine epsilon will not be enough given the number of operations that could have gone into these numbers. We could take two approaches here:</p>\n<ol>\n<li>we could just trust that the input at this stage is correct and let GMTK deal with any deviations from adding up to 1.0. I assume that it already does this just fine. We should check user input closer to the user but not here. I think I would favor this, if that\u2019s the case; or</li>\n<li>we could rescale <code>mean_prior_vector</code>, multiplying each cell by the inverse of <code>sum(mean_prior_vector)</code>. That would ensure it adds up to <code>1.0</code> as best we can manage.</li>\n</ol>\n<p>\u200c</p>", "type": "rendered"}, "created_on": "2019-09-27T18:54:11.912033+00:00", "user": {"display_name": "Michael Hoffman", "uuid": "{ffa8e039-5d4d-4f69-a4ba-ac25cbaf700b}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bffa8e039-5d4d-4f69-a4ba-ac25cbaf700b%7D"}, "html": {"href": "https://bitbucket.org/%7Bffa8e039-5d4d-4f69-a4ba-ac25cbaf700b%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/6a95e857a02504cbad5fe965c9d9e4bbd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsMH-1.png"}}, "nickname": "hoffman", "type": "user", "account_id": "557058:a9657985-692c-405c-995b-4e41cda7ba2b"}, "inline": {"to": 375, "from": null, "outdated": true, "path": "segway/observations.py"}, "updated_on": "2019-09-27T18:54:11.920997+00:00", "type": "pullrequest_comment", "id": 118706621}
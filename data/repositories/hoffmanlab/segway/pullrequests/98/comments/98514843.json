{"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98514843.json"}, "code": {"href": "https://api.bitbucket.org/2.0/repositories/hoffmanlab/segway/diff/rcwchan/segway:0ec5ee955fd5..be63c5ecae34?path=segway%2Fobservations.py"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98514843"}}, "parent": {"id": 98497932, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98497932.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98497932"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "If the list length is not divisible by resolution, then you just have a subarray containing the \u2018remainder\u2019 entries. For example:\n\n```\nimport numpy as np\nresolution = 3\ninput_array = np.arange(0,5)\nresolution_partitioned_input_array = [input_array[index:index+resolution] for index in range(0, len(input_array), resolution)]\n```\n\ngives\n\n`[array([0, 1, 2]), array([3, 4])]`", "markup": "markdown", "html": "<p>If the list length is not divisible by resolution, then you just have a subarray containing the \u2018remainder\u2019 entries. For example:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"kn\">as</span> <span class=\"nn\">np</span>\n<span class=\"n\">resolution</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>\n<span class=\"n\">input_array</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"kp\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"n\">resolution_partitioned_input_array</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">input_array</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"p\">:</span><span class=\"n\">index</span><span class=\"o\">+</span><span class=\"n\">resolution</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">index</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">input_array</span><span class=\"p\">),</span> <span class=\"n\">resolution</span><span class=\"p\">)]</span>\n</pre></div>\n\n\n<p>gives</p>\n<p><code>[array([0, 1, 2]), array([3, 4])]</code></p>", "type": "rendered"}, "created_on": "2019-04-11T17:46:51.824369+00:00", "user": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "inline": {"to": 402, "from": null, "outdated": true, "path": "segway/observations.py"}, "updated_on": "2019-04-11T17:47:08.298595+00:00", "type": "pullrequest_comment", "id": 98514843}
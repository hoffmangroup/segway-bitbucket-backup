{"pagelen": 50, "values": [{"update": {"description": "## Introduction\r\n\r\nThis pull request implements virtual evidence during training \\(disabled during identification\\). It is partly \\(namely the VE structure\\) based off of Max Libbrecht's measure-prop branch.  \r\nSpecifically, a binary virtual evidence node C has been added, which supplies the prior probability that the parent \\(segment label\\) A at a particular position is a particular label \\(ie P\\(C=1|A=a\\)\\).\r\n\r\nIn other words, the binary virtual child C exists only to constrain the parent \\(segment label\\) to be a particular value \\(supervised label\\) with the specified prior probability.\r\n\r\nI have also added a presence node such that positions with no prior specified by the user will have no virtual evidence.\r\n\r\nThe revised part of the graphical model is as below, where Qt is the segment label at position t, Ct is the virtual evidence child, and oCt indicates the presence of Ct. The black dotted line indicates a deterministic dependence where the parent of Ct switches based on the value of oCt; the red line indicates a stochastic conditional dependence \\(as there is a different Ct|Qt CPT at each t.\\) \r\n\r\n![](https://bitbucket.org/repo/a7MnLo/images/3913472725-graph_changes.png)\r\n## User changes\r\n\r\nThere are no changes to users without VE.\r\n\r\nIf a user wishes to use virtual evidence, they should supply a 'virtual evidence file' to Segway with the option `--virtual-evidence`. This virtual evidence file should be of BED3 format where the 4th column is a string containing the label:prior pairs the user wishes to specify, delimited by commas. For example,\r\n\r\n```\r\nchr1    0    1000    0:0.9,1:0.05\r\n```\r\n\r\nSpecifies a prior probability of 0.9 on label 0 and 0.05 on label 1 at chr1\\(0,1000\\).\r\n\r\nAt positions for which some labels are given a prior by the user but other labels not, the remaining probability is uniformly distributed amongst the leftover labels. For example, with 4 labels:\r\n\r\n```\r\nchr1    0    1000    0:0.4\r\n```\r\n\r\nall labels but label 0 would be given a prior probability of \\(1-0.4\\)/3=0.2.\r\n\r\nFor positions at which no prior is specified for all labels, a uniform probability is computed and distributed amongst the labels \\(though given 0 weight by Segway later due to the presence variable\\).\r\n\r\n## How it works\r\n\r\nVirtual evidence is similar to supervision in that values need to be supplied at each GMTK frame \\(with multiple frames per Segway window\\). However, the values supplied are CPTs, not observations, and so it does not work \\(as far as I know\\) to place them in the usual int/float observation files.\r\n\r\nTo this end, I used Segway's existing temporary observation files framework to create temporary CPTs \\(one large CPT per window, with one vector of priors for each GMTK frame in that window\\) and a list of these CPTs \\(`virtual_evidence_list_filename`\\).\r\n\r\nDuring training, the cpp directive `VIRTUAL_EVIDENCE_LIST_FILENAME` is given a value of `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` when creating the task to send to segway-task. `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` is then replaced within the cppCommand string with the temporarily created `virtual_evidence_list_filename` \\(with its list of CPTs per window\\).\r\n\r\nThe presence for virtual evidence is supplied identically as for data and supervision labels--appended to the int block and subsequently passed forwards to GMTK for use.\r\n\r\n## Resolution and downsampling\r\n\r\nIn order to downsample virtual evidence \\(`get_downsampled_virtual_evidence_data_and_presence`\\), I decided to implement the following rule:\r\n\r\nLet resolution be greater than 1. For positions which have some priors specified but not all, compute uniform priors for the remaining labels and take the average prior probability \\(over the position axis\\) over these positions. The presence is then the number of positions that have any priors specified.\r\n\r\nFor example, with 3 total labels with resolution 10:\r\n\r\n```\r\nchr1    0   1    0:0.5,1:0.2\r\nchr1    1    2    1:0.4\r\n```\r\n\r\nthis expands \\(inferring uniform priors for remaining labels\\) into:\r\n\r\n```\r\nlabel           0   1   2\r\nchr1    0   1   0.5 0.2 0.3\r\nchr1    1   2   0.3 0.4 0.3\r\n```\r\n\r\nwe take the average over these positions to obtain:\r\n\r\n```\r\nchr1    0   10  0.4 0.3 0.4\r\n```\r\n\r\nwith presence 2.\r\n\r\nNow let resolution equal 1. Then the presence is simply 1 or 0; 1 for positions with priors specified, and 0 for positions without. For positions with priors specified, uniform priors are inferred for any remaining labels, and this becomes the prior vector for that position.\r\n\r\nIn both cases, positions with no priors specified are given 0 presence and uniform priors for all labels.\r\n\r\n## Test case\r\n\r\nFollowing discussion with Eric, I created the following virtual evidence bedfile and supplied it to simpleseg:\r\n\r\n```\r\nchr1    0   1000    0:0.9\r\nchr1    4000    5000    0:0.9\r\n```\r\n\r\nThis is able to separate the binary 0,0 and 0,1 regions in simpleseg, creating the following annotation:\r\n\r\n```\r\nchr1    0   1000    0   1000    .   0   1000    27,158,119\r\nchr1    1000    2000    1   1000    .   1000    2000    217,95,2\r\nchr1    2000    3000    2   1000    .   2000    3000    117,112,179\r\nchr1    3000    4000    3   1000    .   3000    4000    231,41,138\r\nchr1    4000    5000    0   1000    .   4000    5000    27,158,119\r\nchr1    5000    6000    1   1000    .   5000    6000    217,95,2\r\nchr1    6000    7000    2   1000    .   6000    7000    117,112,179\r\nchr1    7000    8000    3   1000    .   7000    8000    231,41,138\r\n```\r\n\r\nI have named this test case `simplevirtualevidence`.\r\n\r\n## Remaining work\r\n\r\nAs discussed with Max Libbrecht over email, it might be interesting to enable VE during identification \\(allowing priors to influence Viterbi\\) in a future PR.", "title": "Implement virtual evidence during training", "destination": {"commit": {"hash": "e296818322be", "type": "commit", "links": {"self": {"href": "data/repositories/hoffmanlab/segway/commit/e296818322be.json"}, "html": {"href": "#!/hoffmanlab/segway/commits/e296818322be"}}}, "repository": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway.json"}, "html": {"href": "#!/hoffmanlab/segway"}, "avatar": {"href": "data/bytebucket.org/ravatar/{68bf38bf-f0c1-4c9c-909e-0ee4b2c26257}ts=python"}}, "type": "repository", "name": "segway", "full_name": "hoffmanlab/segway", "uuid": "{68bf38bf-f0c1-4c9c-909e-0ee4b2c26257}"}, "branch": {"name": "default"}}, "reason": "", "source": {"commit": {"hash": "1defedc4139a", "type": "commit", "links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/rcwchan/segway/commit/1defedc4139a"}, "html": {"href": "https://bitbucket.org/rcwchan/segway/commits/1defedc4139a"}}}, "repository": {"links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/rcwchan/segway"}, "html": {"href": "https://bitbucket.org/rcwchan/segway"}, "avatar": {"href": "data/bytebucket.org/ravatar/{285886c8-7a4a-4d80-8fe1-3d4b0d9146f6}ts=python"}}, "type": "repository", "name": "segway", "full_name": "rcwchan/segway", "uuid": "{285886c8-7a4a-4d80-8fe1-3d4b0d9146f6}"}, "branch": {"name": "virtualevidence"}}, "state": "OPEN", "author": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "date": "2019-07-29T15:00:39.059903+00:00"}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"update": {"description": "## Introduction\r\n\r\nThis pull request implements virtual evidence during training \\(disabled during identification\\). It is partly \\(namely the VE structure\\) based off of Max Libbrecht's measure-prop branch.  \r\nSpecifically, a binary virtual evidence node C has been added, which supplies the prior probability that the parent \\(segment label\\) A at a particular position is a particular label \\(ie P\\(C=1|A=a\\)\\).\r\n\r\nIn other words, the binary virtual child C exists only to constrain the parent \\(segment label\\) to be a particular value \\(supervised label\\) with the specified prior probability.\r\n\r\nI have also added a presence node such that positions with no prior specified by the user will have no virtual evidence.\r\n\r\nThe revised part of the graphical model is as below, where Qt is the segment label at position t, Ct is the virtual evidence child, and oCt indicates the presence of Ct. The black dotted line indicates a deterministic dependence where the parent of Ct switches based on the value of oCt; the red line indicates a stochastic conditional dependence \\(as there is a different Ct|Qt CPT at each t.\\) \r\n\r\n![](https://bitbucket.org/repo/a7MnLo/images/3913472725-graph_changes.png)\r\n## User changes\r\n\r\nThere are no changes to users without VE.\r\n\r\nIf a user wishes to use virtual evidence, they should supply a 'virtual evidence file' to Segway with the option `--virtual-evidence`. This virtual evidence file should be of BED3 format where the 4th column is a string containing the label:prior pairs the user wishes to specify, delimited by commas. For example,\r\n\r\n```\r\nchr1    0    1000    0:0.9,1:0.05\r\n```\r\n\r\nSpecifies a prior probability of 0.9 on label 0 and 0.05 on label 1 at chr1\\(0,1000\\).\r\n\r\nAt positions for which some labels are given a prior by the user but other labels not, the remaining probability is uniformly distributed amongst the leftover labels. For example, with 4 labels:\r\n\r\n```\r\nchr1    0    1000    0:0.4\r\n```\r\n\r\nall labels but label 0 would be given a prior probability of \\(1-0.4\\)/3=0.2.\r\n\r\nFor positions at which no prior is specified for all labels, a uniform probability is computed and distributed amongst the labels \\(though given 0 weight by Segway later due to the presence variable\\).\r\n\r\n## How it works\r\n\r\nVirtual evidence is similar to supervision in that values need to be supplied at each GMTK frame \\(with multiple frames per Segway window\\). However, the values supplied are CPTs, not observations, and so it does not work \\(as far as I know\\) to place them in the usual int/float observation files.\r\n\r\nTo this end, I used Segway's existing temporary observation files framework to create temporary CPTs \\(one large CPT per window, with one vector of priors for each GMTK frame in that window\\) and a list of these CPTs \\(`virtual_evidence_list_filename`\\).\r\n\r\nDuring training, the cpp directive `VIRTUAL_EVIDENCE_LIST_FILENAME` is given a value of `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` when creating the task to send to segway-task. `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` is then replaced within the cppCommand string with the temporarily created `virtual_evidence_list_filename` \\(with its list of CPTs per window\\).\r\n\r\nThe presence for virtual evidence is supplied identically as for data and supervision labels--appended to the int block and subsequently passed forwards to GMTK for use.\r\n\r\n## Resolution and downsampling\r\n\r\nIn order to downsample virtual evidence \\(`get_downsampled_virtual_evidence_data_and_presence`\\), I decided to implement the following rule:\r\n\r\nLet resolution be greater than 1. For positions which have some priors specified but not all, compute uniform priors for the remaining labels and take the average prior probability \\(over the position axis\\) over these positions. The presence is then the number of positions that have any priors specified.\r\n\r\nFor example, with 3 total labels with resolution 10:\r\n\r\n```\r\nchr1    0   1    0:0.5,1:0.2\r\nchr1    1    2    1:0.4\r\n```\r\n\r\nthis expands \\(inferring uniform priors for remaining labels\\) into:\r\n\r\n```\r\nlabel           0   1   2\r\nchr1    0   1   0.5 0.2 0.3\r\nchr1    1   2   0.3 0.4 0.3\r\n```\r\n\r\nwe take the average over these positions to obtain:\r\n\r\n```\r\nchr1    0   10  0.4 0.3 0.4\r\n```\r\n\r\nwith presence 2.\r\n\r\nNow let resolution equal 1. Then the presence is simply 1 or 0; 1 for positions with priors specified, and 0 for positions without. For positions with priors specified, uniform priors are inferred for any remaining labels, and this becomes the prior vector for that position.\r\n\r\nIn both cases, positions with no priors specified are given 0 presence and uniform priors for all labels.\r\n\r\n## Test case\r\n\r\nFollowing discussion with Eric, I created the following virtual evidence bedfile and supplied it to simpleseg:\r\n\r\n```\r\nchr1    0   1000    0:0.9\r\nchr1    4000    5000    0:0.9\r\n```\r\n\r\nThis is able to separate the binary 0,0 and 0,1 regions in simpleseg, creating the following annotation:\r\n\r\n```\r\nchr1    0   1000    0   1000    .   0   1000    27,158,119\r\nchr1    1000    2000    1   1000    .   1000    2000    217,95,2\r\nchr1    2000    3000    2   1000    .   2000    3000    117,112,179\r\nchr1    3000    4000    3   1000    .   3000    4000    231,41,138\r\nchr1    4000    5000    0   1000    .   4000    5000    27,158,119\r\nchr1    5000    6000    1   1000    .   5000    6000    217,95,2\r\nchr1    6000    7000    2   1000    .   6000    7000    117,112,179\r\nchr1    7000    8000    3   1000    .   7000    8000    231,41,138\r\n```\r\n\r\nI have named this test case `simplevirtualevidence`.\r\n\r\n## Remaining work\r\n\r\nAs discussed with Max Libbrecht over email, it might be interesting to enable VE during identification \\(allowing priors to influence Viterbi\\) in a future PR.", "title": "Implement virtual evidence during training", "destination": {"commit": {"hash": "b3646a21705d", "type": "commit", "links": {"self": {"href": "data/repositories/hoffmanlab/segway/commit/b3646a21705d.json"}, "html": {"href": "#!/hoffmanlab/segway/commits/b3646a21705d"}}}, "repository": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway.json"}, "html": {"href": "#!/hoffmanlab/segway"}, "avatar": {"href": "data/bytebucket.org/ravatar/{68bf38bf-f0c1-4c9c-909e-0ee4b2c26257}ts=python"}}, "type": "repository", "name": "segway", "full_name": "hoffmanlab/segway", "uuid": "{68bf38bf-f0c1-4c9c-909e-0ee4b2c26257}"}, "branch": {"name": "default"}}, "reason": "", "source": {"commit": {"hash": "75352e72d7dd", "type": "commit", "links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/rcwchan/segway/commit/75352e72d7dd"}, "html": {"href": "https://bitbucket.org/rcwchan/segway/commits/75352e72d7dd"}}}, "repository": {"links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/rcwchan/segway"}, "html": {"href": "https://bitbucket.org/rcwchan/segway"}, "avatar": {"href": "data/bytebucket.org/ravatar/{285886c8-7a4a-4d80-8fe1-3d4b0d9146f6}ts=python"}}, "type": "repository", "name": "segway", "full_name": "rcwchan/segway", "uuid": "{285886c8-7a4a-4d80-8fe1-3d4b0d9146f6}"}, "branch": {"name": "virtualevidence"}}, "state": "OPEN", "author": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "date": "2019-05-23T22:14:21.320166+00:00"}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"update": {"description": "## Introduction\r\n\r\nThis pull request implements virtual evidence during training \\(disabled during identification\\). It is partly \\(namely the VE structure\\) based off of Max Libbrecht's measure-prop branch.  \r\nSpecifically, a binary virtual evidence node C has been added, which supplies the prior probability that the parent \\(segment label\\) A at a particular position is a particular label \\(ie P\\(C=1|A=a\\)\\).\r\n\r\nIn other words, the binary virtual child C exists only to constrain the parent \\(segment label\\) to be a particular value \\(supervised label\\) with the specified prior probability.\r\n\r\nI have also added a presence node such that positions with no prior specified by the user will have no virtual evidence.\r\n\r\nThe revised part of the graphical model is as below, where Qt is the segment label at position t, Ct is the virtual evidence child, and oCt indicates the presence of Ct. The black dotted line indicates a deterministic dependence where the parent of Ct switches based on the value of oCt; the red line indicates a stochastic conditional dependence \\(as there is a different Ct|Qt CPT at each t.\\) \r\n\r\n![](https://bitbucket.org/repo/a7MnLo/images/3913472725-graph_changes.png)\r\n## User changes\r\n\r\nThere are no changes to users without VE.\r\n\r\nIf a user wishes to use virtual evidence, they should supply a 'virtual evidence file' to Segway with the option `--virtual-evidence`. This virtual evidence file should be of BED3 format where the 4th column is a string containing the label:prior pairs the user wishes to specify, delimited by commas. For example,\r\n\r\n```\r\nchr1    0    1000    0:0.9,1:0.05\r\n```\r\n\r\nSpecifies a prior probability of 0.9 on label 0 and 0.05 on label 1 at chr1\\(0,1000\\).\r\n\r\nAt positions for which some labels are given a prior by the user but other labels not, the remaining probability is uniformly distributed amongst the leftover labels. For example, with 4 labels:\r\n\r\n```\r\nchr1    0    1000    0:0.4\r\n```\r\n\r\nall labels but label 0 would be given a prior probability of \\(1-0.4\\)/3=0.2.\r\n\r\nFor positions at which no prior is specified for all labels, a uniform probability is computed and distributed amongst the labels \\(though given 0 weight by Segway later due to the presence variable\\).\r\n\r\n## How it works\r\n\r\nVirtual evidence is similar to supervision in that values need to be supplied at each GMTK frame \\(with multiple frames per Segway window\\). However, the values supplied are CPTs, not observations, and so it does not work \\(as far as I know\\) to place them in the usual int/float observation files.\r\n\r\nTo this end, I used Segway's existing temporary observation files framework to create temporary CPTs \\(one large CPT per window, with one vector of priors for each GMTK frame in that window\\) and a list of these CPTs \\(`virtual_evidence_list_filename`\\).\r\n\r\nDuring training, the cpp directive `VIRTUAL_EVIDENCE_LIST_FILENAME` is given a value of `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` when creating the task to send to segway-task. `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` is then replaced within the cppCommand string with the temporarily created `virtual_evidence_list_filename` \\(with its list of CPTs per window\\).\r\n\r\nThe presence for virtual evidence is supplied identically as for data and supervision labels--appended to the int block and subsequently passed forwards to GMTK for use.\r\n\r\n## Resolution and downsampling\r\n\r\nIn order to downsample virtual evidence \\(`get_downsampled_virtual_evidence_data_and_presence`\\), I decided to implement the following rule:\r\n\r\nLet resolution be greater than 1. For positions which have some priors specified but not all, compute uniform priors for the remaining labels and take the average prior probability \\(over the position axis\\) over these positions. The presence is then the number of positions that have any priors specified.\r\n\r\nFor example, with 3 total labels with resolution 10:\r\n\r\n```\r\nchr1    0   1    0:0.5,1:0.2\r\nchr1    1    2    1:0.4\r\n```\r\n\r\nthis expands \\(inferring uniform priors for remaining labels\\) into:\r\n\r\n```\r\nlabel           0   1   2\r\nchr1    0   1   0.5 0.2 0.3\r\nchr1    1   2   0.3 0.4 0.3\r\n```\r\n\r\nwe take the average over these positions to obtain:\r\n\r\n```\r\nchr1    0   10  0.4 0.3 0.4\r\n```\r\n\r\nwith presence 2.\r\n\r\nNow let resolution equal 1. Then the presence is simply 1 or 0; 1 for positions with priors specified, and 0 for positions without. For positions with priors specified, uniform priors are inferred for any remaining labels, and this becomes the prior vector for that position.\r\n\r\nIn both cases, positions with no priors specified are given 0 presence and uniform priors for all labels.\r\n\r\n## Test case\r\n\r\nFollowing discussion with Eric, I created the following virtual evidence bedfile and supplied it to simpleseg:\r\n\r\n```\r\nchr1    0   1000    0:0.9\r\nchr1    4000    5000    0:0.9\r\n```\r\n\r\nThis is able to separate the binary 0,0 and 0,1 regions in simpleseg, creating the following annotation:\r\n\r\n```\r\nchr1    0   1000    0   1000    .   0   1000    27,158,119\r\nchr1    1000    2000    1   1000    .   1000    2000    217,95,2\r\nchr1    2000    3000    2   1000    .   2000    3000    117,112,179\r\nchr1    3000    4000    3   1000    .   3000    4000    231,41,138\r\nchr1    4000    5000    0   1000    .   4000    5000    27,158,119\r\nchr1    5000    6000    1   1000    .   5000    6000    217,95,2\r\nchr1    6000    7000    2   1000    .   6000    7000    117,112,179\r\nchr1    7000    8000    3   1000    .   7000    8000    231,41,138\r\n```\r\n\r\nI have named this test case `simplevirtualevidence`.\r\n\r\n## Remaining work\r\n\r\nAs discussed with Max Libbrecht over email, it might be interesting to enable VE during identification \\(allowing priors to influence Viterbi\\) in a future PR.", "title": "Implement virtual evidence during training", "destination": {"commit": {"hash": "be63c5ecae34", "type": "commit", "links": {"self": {"href": "data/repositories/hoffmanlab/segway/commit/be63c5ecae34.json"}, "html": {"href": "#!/hoffmanlab/segway/commits/be63c5ecae34"}}}, "repository": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway.json"}, "html": {"href": "#!/hoffmanlab/segway"}, "avatar": {"href": "data/bytebucket.org/ravatar/{68bf38bf-f0c1-4c9c-909e-0ee4b2c26257}ts=python"}}, "type": "repository", "name": "segway", "full_name": "hoffmanlab/segway", "uuid": "{68bf38bf-f0c1-4c9c-909e-0ee4b2c26257}"}, "branch": {"name": "default"}}, "reason": "", "source": {"commit": {"hash": "03126e9b7c35", "type": "commit", "links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/rcwchan/segway/commit/03126e9b7c35"}, "html": {"href": "https://bitbucket.org/rcwchan/segway/commits/03126e9b7c35"}}}, "repository": {"links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/rcwchan/segway"}, "html": {"href": "https://bitbucket.org/rcwchan/segway"}, "avatar": {"href": "data/bytebucket.org/ravatar/{285886c8-7a4a-4d80-8fe1-3d4b0d9146f6}ts=python"}}, "type": "repository", "name": "segway", "full_name": "rcwchan/segway", "uuid": "{285886c8-7a4a-4d80-8fe1-3d4b0d9146f6}"}, "branch": {"name": "virtualevidence"}}, "state": "OPEN", "author": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "date": "2019-05-16T17:42:31.553503+00:00"}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"update": {"description": "## Introduction\r\n\r\nThis pull request implements virtual evidence during training \\(disabled during identification\\). It is partly \\(namely the VE structure\\) based off of Max Libbrecht's measure-prop branch.  \r\nSpecifically, a binary virtual evidence node C has been added, which supplies the prior probability that the parent \\(segment label\\) A at a particular position is a particular label \\(ie P\\(C=1|A=a\\)\\).\r\n\r\nIn other words, the binary virtual child C exists only to constrain the parent \\(segment label\\) to be a particular value \\(supervised label\\) with the specified prior probability.\r\n\r\nI have also added a presence node such that positions with no prior specified by the user will have no virtual evidence.\r\n\r\nThe revised part of the graphical model is as below, where Qt is the segment label at position t, Ct is the virtual evidence child, and oCt indicates the presence of Ct. The black dotted line indicates a deterministic dependence where the parent of Ct switches based on the value of oCt; the red line indicates a stochastic conditional dependence \\(as there is a different Ct|Qt CPT at each t.\\) \r\n\r\n![](https://bitbucket.org/repo/a7MnLo/images/3913472725-graph_changes.png)\r\n## User changes\r\n\r\nThere are no changes to users without VE.\r\n\r\nIf a user wishes to use virtual evidence, they should supply a 'virtual evidence file' to Segway with the option `--virtual-evidence`. This virtual evidence file should be of BED3 format where the 4th column is a string containing the label:prior pairs the user wishes to specify, delimited by commas. For example,\r\n\r\n```\r\nchr1    0    1000    0:0.9,1:0.05\r\n```\r\n\r\nSpecifies a prior probability of 0.9 on label 0 and 0.05 on label 1 at chr1\\(0,1000\\).\r\n\r\nAt positions for which some labels are given a prior by the user but other labels not, the remaining probability is uniformly distributed amongst the leftover labels. For example, with 4 labels:\r\n\r\n```\r\nchr1    0    1000    0:0.4\r\n```\r\n\r\nall labels but label 0 would be given a prior probability of \\(1-0.4\\)/3=0.2.\r\n\r\nFor positions at which no prior is specified for all labels, a uniform probability is computed and distributed amongst the labels \\(though given 0 weight by Segway later due to the presence variable\\).\r\n\r\n## How it works\r\n\r\nVirtual evidence is similar to supervision in that values need to be supplied at each GMTK frame \\(with multiple frames per Segway window\\). However, the values supplied are CPTs, not observations, and so it does not work \\(as far as I know\\) to place them in the usual int/float observation files.\r\n\r\nTo this end, I used Segway's existing temporary observation files framework to create temporary CPTs \\(one large CPT per window, with one vector of priors for each GMTK frame in that window\\) and a list of these CPTs \\(`virtual_evidence_list_filename`\\).\r\n\r\nDuring training, the cpp directive `VIRTUAL_EVIDENCE_LIST_FILENAME` is given a value of `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` when creating the task to send to segway-task. `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` is then replaced within the cppCommand string with the temporarily created `virtual_evidence_list_filename` \\(with its list of CPTs per window\\).\r\n\r\nThe presence for virtual evidence is supplied identically as for data and supervision labels--appended to the int block and subsequently passed forwards to GMTK for use.\r\n\r\n## Resolution and downsampling\r\n\r\nIn order to downsample virtual evidence \\(`get_downsampled_virtual_evidence_data_and_presence`\\), I decided to implement the following rule:\r\n\r\nLet resolution be greater than 1. For positions which have some priors specified but not all, compute uniform priors for the remaining labels and take the average prior probability \\(over the position axis\\) over these positions. The presence is then the number of positions that have any priors specified.\r\n\r\nFor example, with 3 total labels with resolution 10:\r\n\r\n```\r\nchr1    0   1    0:0.5,1:0.2\r\nchr1    1    2    1:0.4\r\n```\r\n\r\nthis expands \\(inferring uniform priors for remaining labels\\) into:\r\n\r\n```\r\nlabel           0   1   2\r\nchr1    0   1   0.5 0.2 0.3\r\nchr1    1   2   0.3 0.4 0.3\r\n```\r\n\r\nwe take the average over these positions to obtain:\r\n\r\n```\r\nchr1    0   10  0.4 0.3 0.4\r\n```\r\n\r\nwith presence 2.\r\n\r\nNow let resolution equal 1. Then the presence is simply 1 or 0; 1 for positions with priors specified, and 0 for positions without. For positions with priors specified, uniform priors are inferred for any remaining labels, and this becomes the prior vector for that position.\r\n\r\nIn both cases, positions with no priors specified are given 0 presence and uniform priors for all labels.\r\n\r\n## Test case\r\n\r\nFollowing discussion with Eric, I created the following virtual evidence bedfile and supplied it to simpleseg:\r\n\r\n```\r\nchr1    0   1000    0:0.9\r\nchr1    4000    5000    0:0.9\r\n```\r\n\r\nThis is able to separate the binary 0,0 and 0,1 regions in simpleseg, creating the following annotation:\r\n\r\n```\r\nchr1    0   1000    0   1000    .   0   1000    27,158,119\r\nchr1    1000    2000    1   1000    .   1000    2000    217,95,2\r\nchr1    2000    3000    2   1000    .   2000    3000    117,112,179\r\nchr1    3000    4000    3   1000    .   3000    4000    231,41,138\r\nchr1    4000    5000    0   1000    .   4000    5000    27,158,119\r\nchr1    5000    6000    1   1000    .   5000    6000    217,95,2\r\nchr1    6000    7000    2   1000    .   6000    7000    117,112,179\r\nchr1    7000    8000    3   1000    .   7000    8000    231,41,138\r\n```\r\n\r\nI have named this test case `simplevirtualevidence`.\r\n\r\n## Remaining work\r\n\r\nAs discussed with Max Libbrecht over email, it might be interesting to enable VE during identification \\(allowing priors to influence Viterbi\\) in a future PR.", "title": "Implement virtual evidence during training", "destination": {"commit": {"hash": "be63c5ecae34", "type": "commit", "links": {"self": {"href": "data/repositories/hoffmanlab/segway/commit/be63c5ecae34.json"}, "html": {"href": "#!/hoffmanlab/segway/commits/be63c5ecae34"}}}, "repository": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway.json"}, "html": {"href": "#!/hoffmanlab/segway"}, "avatar": {"href": "data/bytebucket.org/ravatar/{68bf38bf-f0c1-4c9c-909e-0ee4b2c26257}ts=python"}}, "type": "repository", "name": "segway", "full_name": "hoffmanlab/segway", "uuid": "{68bf38bf-f0c1-4c9c-909e-0ee4b2c26257}"}, "branch": {"name": "default"}}, "reason": "", "source": {"commit": {"hash": "06812d380f71", "type": "commit", "links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/rcwchan/segway/commit/06812d380f71"}, "html": {"href": "https://bitbucket.org/rcwchan/segway/commits/06812d380f71"}}}, "repository": {"links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/rcwchan/segway"}, "html": {"href": "https://bitbucket.org/rcwchan/segway"}, "avatar": {"href": "data/bytebucket.org/ravatar/{285886c8-7a4a-4d80-8fe1-3d4b0d9146f6}ts=python"}}, "type": "repository", "name": "segway", "full_name": "rcwchan/segway", "uuid": "{285886c8-7a4a-4d80-8fe1-3d4b0d9146f6}"}, "branch": {"name": "virtualevidence"}}, "state": "OPEN", "author": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "date": "2019-05-16T16:15:06.786873+00:00"}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/99035547.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-99035547"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "Documentation or notes should be added to the pull request mentioning how this will currently not working with a concatenated run.", "markup": "markdown", "html": "<p>Documentation or notes should be added to the pull request mentioning how this will currently not working with a concatenated run.</p>", "type": "rendered"}, "created_on": "2019-04-16T20:12:44.474935+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "updated_on": "2019-04-16T20:12:44.490195+00:00", "type": "pullrequest_comment", "id": 99035547}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"update": {"description": "## Introduction\r\n\r\nThis pull request implements virtual evidence during training \\(disabled during identification\\). It is partly \\(namely the VE structure\\) based off of Max Libbrecht's measure-prop branch.  \r\nSpecifically, a binary virtual evidence node C has been added, which supplies the prior probability that the parent \\(segment label\\) A at a particular position is a particular label \\(ie P\\(C=1|A=a\\)\\).\r\n\r\nIn other words, the binary virtual child C exists only to constrain the parent \\(segment label\\) to be a particular value \\(supervised label\\) with the specified prior probability.\r\n\r\nI have also added a presence node such that positions with no prior specified by the user will have no virtual evidence.\r\n\r\nThe revised part of the graphical model is as below, where Qt is the segment label at position t, Ct is the virtual evidence child, and oCt indicates the presence of Ct. The black dotted line indicates a deterministic dependence where the parent of Ct switches based on the value of oCt; the red line indicates a stochastic conditional dependence \\(as there is a different Ct|Qt CPT at each t.\\) \r\n\r\n![](https://bitbucket.org/repo/a7MnLo/images/3913472725-graph_changes.png)\r\n## User changes\r\n\r\nThere are no changes to users without VE.\r\n\r\nIf a user wishes to use virtual evidence, they should supply a 'virtual evidence file' to Segway with the option `--virtual-evidence`. This virtual evidence file should be of BED3 format where the 4th column is a string containing the label:prior pairs the user wishes to specify, delimited by commas. For example,\r\n\r\n```\r\nchr1    0    1000    0:0.9,1:0.05\r\n```\r\n\r\nSpecifies a prior probability of 0.9 on label 0 and 0.05 on label 1 at chr1\\(0,1000\\).\r\n\r\nAt positions for which some labels are given a prior by the user but other labels not, the remaining probability is uniformly distributed amongst the leftover labels. For example, with 4 labels:\r\n\r\n```\r\nchr1    0    1000    0:0.4\r\n```\r\n\r\nall labels but label 0 would be given a prior probability of \\(1-0.4\\)/3=0.2.\r\n\r\nFor positions at which no prior is specified for all labels, a uniform probability is computed and distributed amongst the labels \\(though given 0 weight by Segway later due to the presence variable\\).\r\n\r\n## How it works\r\n\r\nVirtual evidence is similar to supervision in that values need to be supplied at each GMTK frame \\(with multiple frames per Segway window\\). However, the values supplied are CPTs, not observations, and so it does not work \\(as far as I know\\) to place them in the usual int/float observation files.\r\n\r\nTo this end, I used Segway's existing temporary observation files framework to create temporary CPTs \\(one large CPT per window, with one vector of priors for each GMTK frame in that window\\) and a list of these CPTs \\(`virtual_evidence_list_filename`\\).\r\n\r\nDuring training, the cpp directive `VIRTUAL_EVIDENCE_LIST_FILENAME` is given a value of `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` when creating the task to send to segway-task. `VIRTUAL_EVIDENCE_LIST_FILENAME_PLACEHOLDER` is then replaced within the cppCommand string with the temporarily created `virtual_evidence_list_filename` \\(with its list of CPTs per window\\).\r\n\r\nThe presence for virtual evidence is supplied identically as for data and supervision labels--appended to the int block and subsequently passed forwards to GMTK for use.\r\n\r\n## Resolution and downsampling\r\n\r\nIn order to downsample virtual evidence \\(`get_downsampled_virtual_evidence_data_and_presence`\\), I decided to implement the following rule:\r\n\r\nLet resolution be greater than 1. For positions which have some priors specified but not all, compute uniform priors for the remaining labels and take the average prior probability \\(over the position axis\\) over these positions. The presence is then the number of positions that have any priors specified.\r\n\r\nFor example, with 3 total labels with resolution 10:\r\n\r\n```\r\nchr1    0   1    0:0.5,1:0.2\r\nchr1    1    2    1:0.4\r\n```\r\n\r\nthis expands \\(inferring uniform priors for remaining labels\\) into:\r\n\r\n```\r\nlabel           0   1   2\r\nchr1    0   1   0.5 0.2 0.3\r\nchr1    1   2   0.3 0.4 0.3\r\n```\r\n\r\nwe take the average over these positions to obtain:\r\n\r\n```\r\nchr1    0   10  0.4 0.3 0.4\r\n```\r\n\r\nwith presence 2.\r\n\r\nNow let resolution equal 1. Then the presence is simply 1 or 0; 1 for positions with priors specified, and 0 for positions without. For positions with priors specified, uniform priors are inferred for any remaining labels, and this becomes the prior vector for that position.\r\n\r\nIn both cases, positions with no priors specified are given 0 presence and uniform priors for all labels.\r\n\r\n## Test case\r\n\r\nFollowing discussion with Eric, I created the following virtual evidence bedfile and supplied it to simpleseg:\r\n\r\n```\r\nchr1    0   1000    0:0.9\r\nchr1    4000    5000    0:0.9\r\n```\r\n\r\nThis is able to separate the binary 0,0 and 0,1 regions in simpleseg, creating the following annotation:\r\n\r\n```\r\nchr1    0   1000    0   1000    .   0   1000    27,158,119\r\nchr1    1000    2000    1   1000    .   1000    2000    217,95,2\r\nchr1    2000    3000    2   1000    .   2000    3000    117,112,179\r\nchr1    3000    4000    3   1000    .   3000    4000    231,41,138\r\nchr1    4000    5000    0   1000    .   4000    5000    27,158,119\r\nchr1    5000    6000    1   1000    .   5000    6000    217,95,2\r\nchr1    6000    7000    2   1000    .   6000    7000    117,112,179\r\nchr1    7000    8000    3   1000    .   7000    8000    231,41,138\r\n```\r\n\r\nI have named this test case `simplevirtualevidence`.\r\n\r\n## Remaining work\r\n\r\nAs discussed with Max Libbrecht over email, it might be interesting to enable VE during identification \\(allowing priors to influence Viterbi\\) in a future PR.", "title": "Implement virtual evidence during training", "destination": {"commit": {"hash": "be63c5ecae34", "type": "commit", "links": {"self": {"href": "data/repositories/hoffmanlab/segway/commit/be63c5ecae34.json"}, "html": {"href": "#!/hoffmanlab/segway/commits/be63c5ecae34"}}}, "repository": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway.json"}, "html": {"href": "#!/hoffmanlab/segway"}, "avatar": {"href": "data/bytebucket.org/ravatar/{68bf38bf-f0c1-4c9c-909e-0ee4b2c26257}ts=python"}}, "type": "repository", "name": "segway", "full_name": "hoffmanlab/segway", "uuid": "{68bf38bf-f0c1-4c9c-909e-0ee4b2c26257}"}, "branch": {"name": "default"}}, "reason": "", "source": {"commit": {"hash": "4f016a2e77ea", "type": "commit", "links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/rcwchan/segway/commit/4f016a2e77ea"}, "html": {"href": "https://bitbucket.org/rcwchan/segway/commits/4f016a2e77ea"}}}, "repository": {"links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/rcwchan/segway"}, "html": {"href": "https://bitbucket.org/rcwchan/segway"}, "avatar": {"href": "data/bytebucket.org/ravatar/{285886c8-7a4a-4d80-8fe1-3d4b0d9146f6}ts=python"}}, "type": "repository", "name": "segway", "full_name": "rcwchan/segway", "uuid": "{285886c8-7a4a-4d80-8fe1-3d4b0d9146f6}"}, "branch": {"name": "virtualevidence"}}, "state": "OPEN", "author": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "date": "2019-04-16T19:13:59.979417+00:00"}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/99027405.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-99027405"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "@rcwchan Okay I think I\u2019ve done a first round of review. Please update as necessary and I will review again.", "markup": "markdown", "html": "<p>@rcwchan Okay I think I\u2019ve done a first round of review. Please update as necessary and I will review again.</p>", "type": "rendered"}, "created_on": "2019-04-16T18:56:57.737409+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "updated_on": "2019-04-16T18:56:57.750611+00:00", "type": "pullrequest_comment", "id": 99027405}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/99002465.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-99002465"}}, "parent": {"id": 97982106, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/97982106.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-97982106"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "What is `0,1,2:0.2` meant to convey? That each have probability 0.2? You would have to specify `0:0.2,1:0.2,2:0.2` in that case, yes.\n\nThe notation `0,1,2:0.2` is kind of ambiguous so I'm not sure how I would implement interpreting that--it could mean, for example, to consider only labels 0 1 and 2 \\(out of >3 labels\\) with a specified prior of 0.2 on 2 \\(and redistribute remaining probability to 0 and 1\\). I think it\u2019s probably simplest to leave the prior specification structure as is?", "markup": "markdown", "html": "<p>What is <code>0,1,2:0.2</code> meant to convey? That each have probability 0.2? You would have to specify <code>0:0.2,1:0.2,2:0.2</code> in that case, yes.</p>\n<p>The notation <code>0,1,2:0.2</code> is kind of ambiguous so I'm not sure how I would implement interpreting that--it could mean, for example, to consider only labels 0 1 and 2 (out of &gt;3 labels) with a specified prior of 0.2 on 2 (and redistribute remaining probability to 0 and 1). I think it\u2019s probably simplest to leave the prior specification structure as is?</p>", "type": "rendered"}, "created_on": "2019-04-16T15:47:42.278639+00:00", "user": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "inline": {}, "updated_on": "2019-04-16T15:48:39.483708+00:00", "type": "pullrequest_comment", "id": 99002465}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/99001683.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-99001683"}}, "parent": {"id": 99000712, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/99000712.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-99000712"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "I'm actually not sure what this is, it's copied over from simpleseg and not part of the touchstone \\(notice that it's not `simplevirtualevidence/touchstone/identifydir/log/segway.sh`\\).", "markup": "markdown", "html": "<p>I'm actually not sure what this is, it's copied over from simpleseg and not part of the touchstone (notice that it's not <code>simplevirtualevidence/touchstone/identifydir/log/segway.sh</code>).</p>", "type": "rendered"}, "created_on": "2019-04-16T15:42:48.033368+00:00", "user": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "inline": {}, "updated_on": "2019-04-16T15:44:15.016997+00:00", "type": "pullrequest_comment", "id": 99001683}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/99001475.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-99001475"}}, "parent": {"id": 99001051, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/99001051.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-99001051"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "OK. That makes sense since I believe stdout is captured to be parsed as well.", "markup": "markdown", "html": "<p>OK. That makes sense since I believe stdout is captured to be parsed as well.</p>", "type": "rendered"}, "created_on": "2019-04-16T15:41:41.139670+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-16T15:41:41.154791+00:00", "type": "pullrequest_comment", "id": 99001475}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/99001051.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-99001051"}}, "parent": {"id": 98999351, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98999351.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98999351"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "There is no error so the error output is empty?\n\nIt\u2019s empty in simpleseg as well:\n\n```\n(base) rachelc@mhoffman8: identify$ ll  /scratch/segway_VE/segway/test/simpleseg/touchstone/identifydir/output/e/identify/vit0.identifydir.\\(%\\[0-9a-f\\]\\{32\\}%\\)\n-rw-r--r-- 1 rachelc mhoffma1 0 Apr  2 13:59 /scratch/segway_VE/segway/test/simpleseg/touchstone/identifydir/output/e/identify/vit0.identifydir.(%[0-9a-f]{32}%)\n```\n\nDo we expect output here?", "markup": "markdown", "html": "<p>There is no error so the error output is empty?</p>\n<p>It\u2019s empty in simpleseg as well:</p>\n<div class=\"codehilite\"><pre><span></span>(base) rachelc@mhoffman8: identify$ ll  /scratch/segway_VE/segway/test/simpleseg/touchstone/identifydir/output/e/identify/vit0.identifydir.\\(%\\[0-9a-f\\]\\{32\\}%\\)\n-rw-r--r-- 1 rachelc mhoffma1 0 Apr  2 13:59 /scratch/segway_VE/segway/test/simpleseg/touchstone/identifydir/output/e/identify/vit0.identifydir.(%[0-9a-f]{32}%)\n</pre></div>\n\n\n<p>Do we expect output here?</p>", "type": "rendered"}, "created_on": "2019-04-16T15:39:26.178435+00:00", "user": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "inline": {}, "updated_on": "2019-04-16T15:39:46.170026+00:00", "type": "pullrequest_comment", "id": 99001051}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/99000712.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-99000712"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "This likely needs to be regexed correct?", "markup": "markdown", "html": "<p>This likely needs to be regexed correct?</p>", "type": "rendered"}, "created_on": "2019-04-16T15:37:31.473505+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-16T15:37:31.487007+00:00", "type": "pullrequest_comment", "id": 99000712}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98999351.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98999351"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "Why are these empty?", "markup": "markdown", "html": "<p>Why are these empty?</p>", "type": "rendered"}, "created_on": "2019-04-16T15:29:45.344931+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-16T15:29:45.353398+00:00", "type": "pullrequest_comment", "id": 98999351}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98996447.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98996447"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "Is virtual evidence necessary here at all for the bundle / maximization stage? The GMTK observation lists are there because they are necessary only for it not to crash. I believe the GMTK observation lists are kept intentionally empty at this stage and/or refer to the files `/dev/null`.", "markup": "markdown", "html": "<p>Is virtual evidence necessary here at all for the bundle / maximization stage? The GMTK observation lists are there because they are necessary only for it not to crash. I believe the GMTK observation lists are kept intentionally empty at this stage and/or refer to the files <code>/dev/null</code>.</p>", "type": "rendered"}, "created_on": "2019-04-16T15:14:28.268616+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-16T15:14:36.636818+00:00", "type": "pullrequest_comment", "id": 98996447}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98865103.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98865103"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "This is a bit confusing since I'm certain you're not actually writing out any GMTK observations here. These are for the CPT tables correct? Maybe `virtual_evidence_cpt_list_fd` ?", "markup": "markdown", "html": "<p>This is a bit confusing since I'm certain you're not actually writing out any GMTK observations here. These are for the CPT tables correct? Maybe <code>virtual_evidence_cpt_list_fd</code> ?</p>", "type": "rendered"}, "created_on": "2019-04-15T20:47:34.994816+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-16T14:57:51.817609+00:00", "type": "pullrequest_comment", "id": 98865103}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98865404.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98865404"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "In general the nomenclature of saving observations as applied to CPT tables is really confusing and probably needs to be reorganized a bit.", "markup": "markdown", "html": "<p>In general the nomenclature of saving observations as applied to CPT tables is really confusing and probably needs to be reorganized a bit.</p>", "type": "rendered"}, "created_on": "2019-04-15T20:50:44.378677+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-15T20:50:44.386726+00:00", "type": "pullrequest_comment", "id": 98865404}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98865195.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98865195"}}, "parent": {"id": 98865103, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98865103.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98865103"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "Also this does not belong in saving temporary observation filelists if this is not actually an observation filelist for GMTK.", "markup": "markdown", "html": "<p>Also this does not belong in saving temporary observation filelists if this is not actually an observation filelist for GMTK.</p>", "type": "rendered"}, "created_on": "2019-04-15T20:48:30.197102+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-15T20:48:30.206563+00:00", "type": "pullrequest_comment", "id": 98865195}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98839240.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98839240"}}, "parent": {"id": 98514648, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98514648.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98514648"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "OK, could you get rid of the `zeros` comment then?\n\nMaybe consider changing the list comprehension with the throw-away parameter with something like `[{}]*(end-start)`.", "markup": "markdown", "html": "<p>OK, could you get rid of the <code>zeros</code> comment then?</p>\n<p>Maybe consider changing the list comprehension with the throw-away parameter with something like <code>[{}]*(end-start)</code>.</p>", "type": "rendered"}, "created_on": "2019-04-15T16:50:51.568672+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-15T16:50:51.584560+00:00", "type": "pullrequest_comment", "id": 98839240}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98837590.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98837590"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "Documentation will need to be updated on how to use this feature, how to specify input, what tracknames are now blacklisted, etc.", "markup": "markdown", "html": "<p>Documentation will need to be updated on how to use this feature, how to specify input, what tracknames are now blacklisted, etc.</p>", "type": "rendered"}, "created_on": "2019-04-15T16:37:19.791616+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "updated_on": "2019-04-15T16:37:19.800289+00:00", "type": "pullrequest_comment", "id": 98837590}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98837496.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98837496"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "Not sure passing an argument for context on an error message is a great idea. You may want to consider catching, getting the original message and providing context if necessary. There are only two calls to this function afaik.", "markup": "markdown", "html": "<p>Not sure passing an argument for context on an error message is a great idea. You may want to consider catching, getting the original message and providing context if necessary. There are only two calls to this function afaik.</p>", "type": "rendered"}, "created_on": "2019-04-15T16:36:35.058047+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-15T16:36:35.069014+00:00", "type": "pullrequest_comment", "id": 98837496}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98516175.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98516175"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "can just `return self.virtual_evidence_filename and self.train`", "markup": "markdown", "html": "<p>can just <code>return self.virtual_evidence_filename and self.train</code></p>", "type": "rendered"}, "created_on": "2019-04-11T17:57:54.913328+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T17:57:54.925922+00:00", "type": "pullrequest_comment", "id": 98516175}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98515430.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98515430"}}, "parent": {"id": 98514425, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98514425.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98514425"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "Returns the user-specified prior vector corresponding to the coordinates in `virtual_evidence_coords`. Then from my understanding, `supercontig_coords_labels` \\(should have a better name, sorry\\) returns a list \\(or generator?\\) of tuples of format \u2018VE label start, VE label end, prior vector in this segment\u2019 for which VE label start and VE label end segments contained within start,end.", "markup": "markdown", "html": "<p>Returns the user-specified prior vector corresponding to the coordinates in <code>virtual_evidence_coords</code>. Then from my understanding, <code>supercontig_coords_labels</code> (should have a better name, sorry) returns a list (or generator?) of tuples of format \u2018VE label start, VE label end, prior vector in this segment\u2019 for which VE label start and VE label end segments contained within start,end.</p>", "type": "rendered"}, "created_on": "2019-04-11T17:51:45.282856+00:00", "user": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "inline": {}, "updated_on": "2019-04-11T17:51:45.294667+00:00", "type": "pullrequest_comment", "id": 98515430}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98515019.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98515019"}}, "parent": {"id": 98514680, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98514680.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98514680"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "The name `num_segs` derives from the internal Segway variable `self.num_segs`, so is it still a good idea to diverge from this?", "markup": "markdown", "html": "<p>The name <code>num_segs</code> derives from the internal Segway variable <code>self.num_segs</code>, so is it still a good idea to diverge from this?</p>", "type": "rendered"}, "created_on": "2019-04-11T17:48:21.523877+00:00", "user": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "inline": {}, "updated_on": "2019-04-11T17:48:21.537843+00:00", "type": "pullrequest_comment", "id": 98515019}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98514962.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98514962"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "`' '.join(map(str, prior)) + '\\n'`", "markup": "markdown", "html": "<p><code>' '.join(map(str, prior)) + '\\n'</code></p>", "type": "rendered"}, "created_on": "2019-04-11T17:47:50.953279+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T17:47:50.966283+00:00", "type": "pullrequest_comment", "id": 98514962}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98514843.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98514843"}}, "parent": {"id": 98497932, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98497932.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98497932"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "If the list length is not divisible by resolution, then you just have a subarray containing the \u2018remainder\u2019 entries. For example:\n\n```\nimport numpy as np\nresolution = 3\ninput_array = np.arange(0,5)\nresolution_partitioned_input_array = [input_array[index:index+resolution] for index in range(0, len(input_array), resolution)]\n```\n\ngives\n\n`[array([0, 1, 2]), array([3, 4])]`", "markup": "markdown", "html": "<p>If the list length is not divisible by resolution, then you just have a subarray containing the \u2018remainder\u2019 entries. For example:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"kn\">as</span> <span class=\"nn\">np</span>\n<span class=\"n\">resolution</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>\n<span class=\"n\">input_array</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"kp\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"n\">resolution_partitioned_input_array</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">input_array</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"p\">:</span><span class=\"n\">index</span><span class=\"o\">+</span><span class=\"n\">resolution</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">index</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">input_array</span><span class=\"p\">),</span> <span class=\"n\">resolution</span><span class=\"p\">)]</span>\n</pre></div>\n\n\n<p>gives</p>\n<p><code>[array([0, 1, 2]), array([3, 4])]</code></p>", "type": "rendered"}, "created_on": "2019-04-11T17:46:51.824369+00:00", "user": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "inline": {}, "updated_on": "2019-04-11T17:47:08.298595+00:00", "type": "pullrequest_comment", "id": 98514843}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98514745.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98514745"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "Remove commented/dead out code", "markup": "markdown", "html": "<p>Remove commented/dead out code</p>", "type": "rendered"}, "created_on": "2019-04-11T17:45:53.861561+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T17:45:53.869961+00:00", "type": "pullrequest_comment", "id": 98514745}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98514680.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98514680"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "May want to rename to `num_labels` here too.", "markup": "markdown", "html": "<p>May want to rename to <code>num_labels</code> here too.</p>", "type": "rendered"}, "created_on": "2019-04-11T17:45:23.683901+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T17:45:23.689766+00:00", "type": "pullrequest_comment", "id": 98514680}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98514648.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98514648"}}, "parent": {"id": 98510784, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98510784.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98510784"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "I initialized a list of empty dictionaries so that the type of all objects in the list are the same. I am returning the list 'res' at the end. `[data]*(number of positions)` broadcasts data to the specified number of positions, for example:\n\n```\n>>> import numpy as np\n>>> data = {1: 0.1}\n>>> end=10\n>>> start = 2\n>>> res = [{} for _ in range(end-start)]\n>>> res\n[{}, {}, {}, {}, {}, {}, {}, {}]\n>>> res[3:5] = [data] * (2)\n>>> res\n[{}, {}, {}, {1: 0.1}, {1: 0.1}, {}, {}, {}]\n```", "markup": "markdown", "html": "<p>I initialized a list of empty dictionaries so that the type of all objects in the list are the same. I am returning the list 'res' at the end. <code>[data]*(number of positions)</code> broadcasts data to the specified number of positions, for example:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"kn\">as</span> <span class=\"nn\">np</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"mi\">1</span><span class=\"p\">:</span> <span class=\"mf\">0.1</span><span class=\"p\">}</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"mi\">10</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"p\">[{}</span> <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">end</span><span class=\"o\">-</span><span class=\"n\">start</span><span class=\"p\">)]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">res</span>\n<span class=\"p\">[{},</span> <span class=\"p\">{},</span> <span class=\"p\">{},</span> <span class=\"p\">{},</span> <span class=\"p\">{},</span> <span class=\"p\">{},</span> <span class=\"p\">{},</span> <span class=\"p\">{}]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">res</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">:</span><span class=\"mi\">5</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">data</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">res</span>\n<span class=\"p\">[{},</span> <span class=\"p\">{},</span> <span class=\"p\">{},</span> <span class=\"p\">{</span><span class=\"mi\">1</span><span class=\"p\">:</span> <span class=\"mf\">0.1</span><span class=\"p\">},</span> <span class=\"p\">{</span><span class=\"mi\">1</span><span class=\"p\">:</span> <span class=\"mf\">0.1</span><span class=\"p\">},</span> <span class=\"p\">{},</span> <span class=\"p\">{},</span> <span class=\"p\">{}]</span>\n</pre></div>", "type": "rendered"}, "created_on": "2019-04-11T17:45:06.887501+00:00", "user": {"display_name": "Rachel Chan", "uuid": "{20430f8d-4e6b-48cc-a8d8-c64868bf7e79}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D"}, "html": {"href": "https://bitbucket.org/%7B20430f8d-4e6b-48cc-a8d8-c64868bf7e79%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/4397abec9f84e35f1f235b350984833dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsRC-1.png"}}, "nickname": "rcwchan", "type": "user", "account_id": "557058:e439e22e-8cfc-4cf1-b090-030d33a0730e"}, "inline": {}, "updated_on": "2019-04-11T17:45:06.911918+00:00", "type": "pullrequest_comment", "id": 98514648}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98514603.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98514603"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "`if virtual_evidence_data:`", "markup": "markdown", "html": "<p><code>if virtual_evidence_data:</code></p>", "type": "rendered"}, "created_on": "2019-04-11T17:44:50.125133+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T17:44:50.132890+00:00", "type": "pullrequest_comment", "id": 98514603}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98514425.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98514425"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "What does the dictionary, `virtual_evidence_priors` of priors do here?", "markup": "markdown", "html": "<p>What does the dictionary, <code>virtual_evidence_priors</code> of priors do here?</p>", "type": "rendered"}, "created_on": "2019-04-11T17:43:32.524163+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T17:43:32.533710+00:00", "type": "pullrequest_comment", "id": 98514425}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98514383.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98514383"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "What is this supposed to represent? What is it meant by \u201clabels\u201d here?", "markup": "markdown", "html": "<p>What is this supposed to represent? What is it meant by \u201clabels\u201d here?</p>", "type": "rendered"}, "created_on": "2019-04-11T17:43:09.770167+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T17:43:09.786032+00:00", "type": "pullrequest_comment", "id": 98514383}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98510826.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98510826"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "These are not \u201csupervision\u201d regions. Please update.", "markup": "markdown", "html": "<p>These are not \u201csupervision\u201d regions. Please update.</p>", "type": "rendered"}, "created_on": "2019-04-11T17:13:04.874554+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T17:13:04.890721+00:00", "type": "pullrequest_comment", "id": 98510826}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98510784.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98510784"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "What is actually happening here? A list of empty dictionaries? Why not initialize to all zero? It looks like you\u2019re returning a list later on.", "markup": "markdown", "html": "<p>What is actually happening here? A list of empty dictionaries? Why not initialize to all zero? It looks like you\u2019re returning a list later on.</p>", "type": "rendered"}, "created_on": "2019-04-11T17:12:39.854901+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T17:12:39.865667+00:00", "type": "pullrequest_comment", "id": 98510784}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98509475.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98509475"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "use zip on `downsampled_prior_array`, `downsampled_presence_array` and `resolution_paritioned_prior_list` to avoid having to keep track of the `index`.", "markup": "markdown", "html": "<p>use zip on <code>downsampled_prior_array</code>, <code>downsampled_presence_array</code> and <code>resolution_paritioned_prior_list</code> to avoid having to keep track of the <code>index</code>.</p>", "type": "rendered"}, "created_on": "2019-04-11T17:00:56.653213+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T17:00:56.666899+00:00", "type": "pullrequest_comment", "id": 98509475}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98501458.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98501458"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "Not sure about the `presence_array` naming here since it's not flagging the presence of a prior or not, but the actual count of priors per position in `input_array`. Maybe `prior_count_list`?", "markup": "markdown", "html": "<p>Not sure about the <code>presence_array</code> naming here since it's not flagging the presence of a prior or not, but the actual count of priors per position in <code>input_array</code>. Maybe <code>prior_count_list</code>?</p>", "type": "rendered"}, "created_on": "2019-04-11T16:00:01.132022+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T16:00:23.017656+00:00", "type": "pullrequest_comment", "id": 98501458}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98501194.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98501194"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "`array(map(len, input_array))`", "markup": "markdown", "html": "<p><code>array(map(len, input_array))</code></p>", "type": "rendered"}, "created_on": "2019-04-11T15:58:16.854552+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T15:58:16.864947+00:00", "type": "pullrequest_comment", "id": 98501194}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98499600.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98499600"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "Better to show how this is working on a list of list instead of the single list since that\u2019s what is actually being operated on", "markup": "markdown", "html": "<p>Better to show how this is working on a list of list instead of the single list since that\u2019s what is actually being operated on</p>", "type": "rendered"}, "created_on": "2019-04-11T15:48:59.663724+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T15:48:59.674605+00:00", "type": "pullrequest_comment", "id": 98499600}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98499434.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98499434"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "Maybe \u201cGroup lists of priors by the input resolution\u201d?", "markup": "markdown", "html": "<p>Maybe \u201cGroup lists of priors by the input resolution\u201d?</p>", "type": "rendered"}, "created_on": "2019-04-11T15:48:02.742398+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T15:48:02.758661+00:00", "type": "pullrequest_comment", "id": 98499434}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98497932.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98497932"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "What is the expected behaviour when the `prior_list` is not evenly divisible by `resolution` ?", "markup": "markdown", "html": "<p>What is the expected behaviour when the <code>prior_list</code> is not evenly divisible by <code>resolution</code> ?</p>", "type": "rendered"}, "created_on": "2019-04-11T15:39:40.149066+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T15:39:40.159372+00:00", "type": "pullrequest_comment", "id": 98497932}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98497856.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98497856"}}, "parent": {"id": 98496255, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98496255.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98496255"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "I believe you meant `prior_list` at this point. It's very hard to keep track of the state of the data transformations since `prior_list` is list of a list. It took me a long time to realize you were grouping lists of priors.", "markup": "markdown", "html": "<p>I believe you meant <code>prior_list</code> at this point. It's very hard to keep track of the state of the data transformations since <code>prior_list</code> is list of a list. It took me a long time to realize you were grouping lists of priors.</p>", "type": "rendered"}, "created_on": "2019-04-11T15:39:12.242278+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T15:39:12.257893+00:00", "type": "pullrequest_comment", "id": 98497856}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98496255.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98496255"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "Isn't `input_array` a list of label:prior dictionaries?", "markup": "markdown", "html": "<p>Isn't <code>input_array</code> a list of label:prior dictionaries?</p>", "type": "rendered"}, "created_on": "2019-04-11T15:31:11.826898+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-11T15:31:19.633914+00:00", "type": "pullrequest_comment", "id": 98496255}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98009599.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98009599"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "There should be a clear `else` or comment about the flow follow when the resolution is >1. Perhaps put the conditional for >1 resolution first and the else with the simple case at the end. Having a single point of return from the function \\(at the end\\) would be ideal if possible.", "markup": "markdown", "html": "<p>There should be a clear <code>else</code> or comment about the flow follow when the resolution is &gt;1. Perhaps put the conditional for &gt;1 resolution first and the else with the simple case at the end. Having a single point of return from the function (at the end) would be ideal if possible.</p>", "type": "rendered"}, "created_on": "2019-04-08T19:55:37.096076+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-08T19:55:37.105691+00:00", "type": "pullrequest_comment", "id": 98009599}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98009415.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98009415"}}, "parent": {"id": 98008060, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98008060.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98008060"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "It's not clear what the difference between the `prior_array` created here is and the `prior_list` before it.", "markup": "markdown", "html": "<p>It's not clear what the difference between the <code>prior_array</code> created here is and the <code>prior_list</code> before it.</p>", "type": "rendered"}, "created_on": "2019-04-08T19:54:04.544287+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-08T19:54:04.555212+00:00", "type": "pullrequest_comment", "id": 98009415}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98009326.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98009326"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "If you could break this function down somehow it would be greatly appreciated. It is seems to be doing a lot of things at once and it\u2019s difficult to follow.", "markup": "markdown", "html": "<p>If you could break this function down somehow it would be greatly appreciated. It is seems to be doing a lot of things at once and it\u2019s difficult to follow.</p>", "type": "rendered"}, "created_on": "2019-04-08T19:53:24.716064+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-08T19:53:24.722717+00:00", "type": "pullrequest_comment", "id": 98009326}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98008060.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98008060"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "This was just called `prior_list` previously for the same definition. What\u2019s the difference?", "markup": "markdown", "html": "<p>This was just called <code>prior_list</code> previously for the same definition. What\u2019s the difference?</p>", "type": "rendered"}, "created_on": "2019-04-08T19:41:30.979707+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-08T19:41:30.990538+00:00", "type": "pullrequest_comment", "id": 98008060}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/98007588.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-98007588"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "`1 if prior_dict else 0`", "markup": "markdown", "html": "<p><code>1 if prior_dict else 0</code></p>", "type": "rendered"}, "created_on": "2019-04-08T19:37:14.660203+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-08T19:37:14.669668+00:00", "type": "pullrequest_comment", "id": 98007588}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/97990239.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-97990239"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "`for prior_probablities, prior_dict in zip(prior_list, input_array):`\n\nand replace instances of `prior_list[prior_dict_index]` with `prior_probablities`. I'm not sure about the naming of `prior_probablities` maybe `expanded_prior_list` instead?", "markup": "markdown", "html": "<p><code>for prior_probablities, prior_dict in zip(prior_list, input_array):</code></p>\n<p>and replace instances of <code>prior_list[prior_dict_index]</code> with <code>prior_probablities</code>. I'm not sure about the naming of <code>prior_probablities</code> maybe <code>expanded_prior_list</code> instead?</p>", "type": "rendered"}, "created_on": "2019-04-08T17:06:25.297411+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-08T17:06:25.307725+00:00", "type": "pullrequest_comment", "id": 97990239}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/97989081.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-97989081"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "`if prior_dict:`", "markup": "markdown", "html": "<p><code>if prior_dict:</code></p>", "type": "rendered"}, "created_on": "2019-04-08T16:57:03.352152+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-08T16:57:03.359635+00:00", "type": "pullrequest_comment", "id": 97989081}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/97988856.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-97988856"}}, "parent": {"id": 97987081, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/97987081.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-97987081"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "I could be mistaken since how \u201csignificant\u201d it might be might already be taken into account by \u201cpresence\u201d though I\u2019m not certain so any feedback would be appreciated.", "markup": "markdown", "html": "<p>I could be mistaken since how \u201csignificant\u201d it might be might already be taken into account by \u201cpresence\u201d though I\u2019m not certain so any feedback would be appreciated.</p>", "type": "rendered"}, "created_on": "2019-04-08T16:55:16.707318+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-08T16:55:30.040893+00:00", "type": "pullrequest_comment", "id": 97988856}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}, {"comment": {"links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98/comments/97988473.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98/_/diff#comment-97988473"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}, "content": {"raw": "\u201cExpand input prior dictionaries to a list of prior probabilites for every label\u201d might summarize this a better", "markup": "markdown", "html": "<p>\u201cExpand input prior dictionaries to a list of prior probabilites for every label\u201d might summarize this a better</p>", "type": "rendered"}, "created_on": "2019-04-08T16:52:09.799624+00:00", "user": {"display_name": "Eric Roberts", "uuid": "{cd8c1fe0-28ca-45fb-8ef9-48090b42bb80}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D"}, "html": {"href": "https://bitbucket.org/%7Bcd8c1fe0-28ca-45fb-8ef9-48090b42bb80%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/17548d71dfb29d015b880f48cfc01ca3d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsER-5.png"}}, "nickname": "ericr86", "type": "user", "account_id": "557058:c80ca578-03a1-4ac6-b3ee-50372a3fceee"}, "inline": {}, "updated_on": "2019-04-08T16:52:09.809786+00:00", "type": "pullrequest_comment", "id": 97988473}, "pull_request": {"type": "pullrequest", "id": 98, "links": {"self": {"href": "data/repositories/hoffmanlab/segway/pullrequests/98.json"}, "html": {"href": "#!/hoffmanlab/segway/pull-requests/98"}}, "title": "Implement virtual evidence during training"}}], "next": "data/repositories/hoffmanlab/segway/pullrequests/98/activity_ctx=r5fxAu4ub.json"}